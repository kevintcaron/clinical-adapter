{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import AutoAdapterModel\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "import adapters.composition as ac\n",
    "from transformers import AutoConfig\n",
    "from adapters import AutoAdapterModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import adapters.composition as ac\n",
    "from transformers import AutoConfig\n",
    "from adapters import AutoAdapterModel\n",
    "import adapters.composition as ac\n",
    "from transformers import AutoConfig\n",
    "from adapters import AutoAdapterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred, task_name):\n",
    "    # print(eval_pred)\n",
    "    logits, labels = eval_pred\n",
    "    if task_name == 'ast':\n",
    "      predictions = np.argmax(logits, axis=-1)\n",
    "      accuracy = accuracy_score(labels, predictions)\n",
    "      precision = precision_score(labels, predictions, average='weighted')\n",
    "      recall = recall_score(labels, predictions, average='weighted')\n",
    "      f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "      return {\n",
    "          'accuracy': accuracy,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1,\n",
    "      }\n",
    "    elif task_name == 'ner':\n",
    "      seqeval = evaluate.load(\"seqeval\")\n",
    "      predictions = np.argmax(logits, axis=2)\n",
    "      label_list  = [\"O\", \"B-test\", \"I-test\", \"B-problem\", \"I-problem\", \"B-treatment\", \"I-treatment\"]\n",
    "      true_predictions = [\n",
    "          [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "          for prediction, label in zip(predictions, labels)\n",
    "      ]\n",
    "      true_labels = [\n",
    "          [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "          for prediction, label in zip(predictions, labels)\n",
    "      ]\n",
    "\n",
    "      results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "      return {\n",
    "          \"accuracy\": results[\"overall_accuracy\"],\n",
    "          \"precision\": results[\"overall_precision\"],\n",
    "          \"recall\": results[\"overall_recall\"],\n",
    "          \"f1\": results[\"overall_f1\"]\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT and add adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model_name_or_path = \"bert-base-uncased\"\n",
    "# #pretrained_model_name_or_path = \"emilyalsentzer/Bio_Discharge_Summary_BERT\"\n",
    "# tokenizer  = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, model_max_length=150)\n",
    "# special_tokens_dict = {\"additional_special_tokens\": [\"[entity]\"]}\n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict,False)\n",
    "# model = AutoAdapterModel.from_pretrained(pretrained_model_name_or_path = pretrained_model_name_or_path,\n",
    "#                                          num_labels=3 , id2label = {0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'})\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# # ast = model.load_adapter(\"./adapter_ast_SeqBnConfig_bert/\",with_head=True)\n",
    "# ast = model.load_adapter(r\"adapter-fusion-weights\\bert\\ast\\adapter_ast_SeqBnConfig_clinicalbert\",with_head=True)\n",
    "\n",
    "# #ast = model.load_adapter(\"./adapter_ast_pfeiffer_clinicalbert\",with_head=True)\n",
    "# model.active_adapters = ast\n",
    "# num_params = sum(p.numel() for p in model.base_model.parameters() if p.requires_grad )\n",
    "# print()\n",
    "# print(f\"Number of trainable parameters: {num_params}\")\n",
    "# print()\n",
    "# # How you can acces the labels and the mapping for a pretrained head\n",
    "# print(model.get_labels())\n",
    "# print(model.get_labels_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT or Clinical BERT fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of trainable parameters: 109483008\n",
      "\n",
      "['LABEL_0', 'LABEL_1', 'LABEL_2']\n",
      "{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'}\n"
     ]
    }
   ],
   "source": [
    "# FULL FINE-TUNE BERT\n",
    "pretrained_model_name_or_path = r\"fine-tuned_bert\\ast_full\"\n",
    "tokenizer_path = \"bert-base-uncased\"\n",
    "\n",
    "# FULL FINE-TUNE ClinicalBERT\n",
    "# pretrained_model_name_or_path = r\"fine-tuned_clinicalbert\\ast_full\"\n",
    "# tokenizer_path = \"emilyalsentzer/Bio_Discharge_Summary_BERT\"\n",
    "\n",
    "\n",
    "tokenizer  = AutoTokenizer.from_pretrained(tokenizer_path, model_max_length=150)\n",
    "special_tokens_dict = {\"additional_special_tokens\": [\"[entity]\"]}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict,False)\n",
    "model = AutoAdapterModel.from_pretrained(pretrained_model_name_or_path = pretrained_model_name_or_path,\n",
    "                                         num_labels=3 , id2label = {0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "num_params = sum(p.numel() for p in model.base_model.parameters() if p.requires_grad )\n",
    "print()\n",
    "print(f\"Number of trainable parameters: {num_params}\")\n",
    "print()\n",
    "# How you can acces the labels and the mapping for a pretrained head\n",
    "print(model.get_labels())\n",
    "print(model.get_labels_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "\n",
      "number of beth training records: 73\n",
      "number of partners training records: 97\n",
      "number of all test records: 256\n",
      "total number of all combined records: 426\n",
      "\n",
      "no labels for record-58\n",
      "no labels for 262182942\n",
      "no labels for 0305\n",
      "\n",
      "number of beth records with labels: 72\n",
      "number of partners records with labels: 96\n",
      "number of test records with labels: 255\n",
      "total number of all combined records with labels: 423\n",
      "\n",
      "number of beth_and_partners examples: 6529\n",
      "number of test examples: 11868\n",
      "total number of combined examples: 18397\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ee3799d46c4151b700e86c69ce9308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_runtime': 86.327, 'test_samples_per_second': 75.631, 'test_steps_per_second': 9.464}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, EvalPrediction\n",
    "from utils import AssertionDatai2b2, ConceptDatai2b2\n",
    "from datasets import Dataset, DatasetDict\n",
    "from adapters import AdapterTrainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "preprocessed_data_path = \"Data/preprocessed-data\"\n",
    "train_data_path = \"Data/concept_assertion_relation_training_data\"\n",
    "reference_test_data_path = \"Data/reference_standard_for_test_data\"\n",
    "test_data_path = \"Data/test_data\"\n",
    "ast_i2b2 = AssertionDatai2b2(preprocessed_data_path=preprocessed_data_path,\n",
    "                                 train_data_path=train_data_path,\n",
    "                                 reference_test_data_path=reference_test_data_path,\n",
    "                                 test_data_path=test_data_path)\n",
    "beth_and_partners_data, test_data, all_data = ast_i2b2.load_assertion_i2b2_data()\n",
    "# https://gist.github.com/vincenttzc/ceaa4aca25e53cb8da195f07e7d0af92\n",
    "\n",
    "\n",
    "def tokenize_function_ast(example):\n",
    "    return tokenizer(example[\"new_line\"],   padding=\"max_length\", truncation=True)\n",
    "lbl2id ={'absent': 1 ,'possible': 2, 'present':0}\n",
    "beth_and_partners_data['label_ids']= beth_and_partners_data.apply(lambda x: lbl2id[x['label']],axis=1)\n",
    "ds_train = Dataset.from_pandas(beth_and_partners_data[['label_ids','new_line']])\n",
    "\n",
    "tokenized_ds_train = ds_train.map(tokenize_function_ast)\n",
    "tokenized_ds_train.set_format(\"torch\")\n",
    "\n",
    "# trainer = AdapterTrainer(model,compute_metrics=lambda p: compute_metrics(p, task_name='ast'))\n",
    "# trainer = Trainer(model,compute_metrics=lambda p: compute_metrics(p, task_name='ast'))\n",
    "trainer = Trainer(model, compute_metrics=compute_metrics)\n",
    "outputs = trainer.predict(tokenized_ds_train)\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA SCORES:\n",
      "Micro F1 Score: 0.9932608362689539\n",
      "Macro F1 Score: 0.9833025198050361\n",
      "Class 0: F1 Score = 0.9958945548833189\n",
      "Class 1: F1 Score = 0.9915333960489182\n",
      "Class 2: F1 Score = 0.9624796084828712\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(outputs[0][1], axis=1)\n",
    "y_true = beth_and_partners_data['label_ids']\n",
    "\n",
    "# Micro F1 Score\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "# Macro F1 Score\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(\"TRAINING DATA SCORES:\")\n",
    "print(f\"Micro F1 Score: {micro_f1}\")\n",
    "print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "class_f1_scores = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "# Print F1 scores for each class\n",
    "for class_idx, f1_score_value in enumerate(class_f1_scores):\n",
    "    print(f\"Class {class_idx}: F1 Score = {f1_score_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338b028fcce44a8db5ca7bd56e313219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_runtime': 176.9422,\n",
       " 'test_samples_per_second': 67.073,\n",
       " 'test_steps_per_second': 8.387}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['label_ids']= test_data.apply(lambda x: lbl2id[x['label']],axis=1)\n",
    "ds_test = Dataset.from_pandas(test_data[['label_ids','new_line']])\n",
    "\n",
    "tokenized_ds_test = ds_test.map(tokenize_function_ast)\n",
    "tokenized_ds_test.set_format(\"torch\")\n",
    "\n",
    "# trainer = AdapterTrainer(model,compute_metrics=lambda p: compute_metrics(p, task_name='ast'))\n",
    "test_trainer = Trainer(model,compute_metrics=lambda p: compute_metrics(p, task_name='ast'))\n",
    "test_outputs = test_trainer.predict(tokenized_ds_test)\n",
    "test_outputs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA SCORES:\n",
      "Micro F1 Score: 0.9630097741826761\n",
      "Macro F1 Score: 0.8991750228843692\n",
      "Class 0: F1 Score = 0.9763071424453795\n",
      "Class 1: F1 Score = 0.9668465690053971\n",
      "Class 2: F1 Score = 0.7543713572023313\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = np.argmax(test_outputs[0][1], axis=1)\n",
    "y_true_test = test_data['label_ids']\n",
    "\n",
    "# Micro F1 Score\n",
    "micro_f1_test = f1_score(y_true_test, y_pred_test, average='micro')\n",
    "\n",
    "# Macro F1 Score\n",
    "macro_f1_test = f1_score(y_true_test, y_pred_test, average='macro')\n",
    "print(\"TEST DATA SCORES:\")\n",
    "print(f\"Micro F1 Score: {micro_f1_test}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_test}\")\n",
    "\n",
    "class_f1_scores_test = f1_score(y_true_test, y_pred_test, average=None)\n",
    "\n",
    "# Print F1 scores for each class\n",
    "for class_idx, f1_score_value in enumerate(class_f1_scores_test):\n",
    "    print(f\"Class {class_idx}: F1 Score = {f1_score_value}\") #{'absent': 1 ,'possible': 2, 'present':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test single example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSENT\n",
      "ABSENT\n",
      "PRESENT\n",
      "ABSENT\n",
      "PRESENT\n",
      "ABSENT\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'}\n",
    "sentence = [ \"Patient denies [entity] SOB [entity]\", #ABSENT\n",
    "            \"Patient do not have [entity] fever [entity]\", #ABSENT\n",
    "            \"had [entity] abnormal ett [entity] and referred for cath\", #PRESENT\n",
    "            \"The patient recovered during the night and now denies any [entity] shortness of breath [entity].\", #ABSENT\n",
    "            \"Patient with [entity] severe fever [entity].\", #PRESENT\n",
    "            \"Patient should abstain from [entity] painkillers [entity]\"] #ABSENT\n",
    "model.to('cpu')\n",
    "for s in sentence :\n",
    "  tokenized_input = tokenizer(s, return_tensors=\"pt\", padding=True)\n",
    "  outputs = model(**tokenized_input)\n",
    "  predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "  print(id2label[predicted_labels.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSENT\n",
      "ABSENT\n",
      "POSSIBLE\n",
      "ABSENT\n",
      "PRESENT\n",
      "ABSENT\n"
     ]
    }
   ],
   "source": [
    "# Made up examples intended to trick model\n",
    "id2label = {0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'}\n",
    "sentence = [ \"Patient denies that the have experienced any type of [entity] back pain [entity]\", #ABSENT\n",
    "            \"There was scant evidence of [entity] fever [entity]\", #ABSENT\n",
    "            \"Patient mentioned possibility of [entity] concussion [entity] but x-ray ruled it out\", #ABSENT\n",
    "            \"The patient recovered during the night and now denies any [entity] shortness of breath [entity].\", #ABSENT\n",
    "            \"Patient reported [entity] severe fever [entity] but testing showed no severe fever.\", #ABSENT\n",
    "            \"Patient should abstain from [entity] painkillers [entity]\"] #ABSENT\n",
    "model.to('cpu')\n",
    "for s in sentence :\n",
    "  tokenized_input = tokenizer(s, return_tensors=\"pt\", padding=True)\n",
    "  outputs = model(**tokenized_input)\n",
    "  predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "  print(id2label[predicted_labels.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([30523, 768])\n",
      "bert.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "heads.default.1.weight torch.Size([3, 768])\n",
      "heads.default.1.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
