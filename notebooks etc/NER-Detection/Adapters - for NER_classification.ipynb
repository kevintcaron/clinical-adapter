{"cells":[{"cell_type":"code","source":["pip install accelerate>=0.20.1"],"metadata":{"id":"O6FmBrlbFnQE","executionInfo":{"status":"ok","timestamp":1701269663025,"user_tz":-330,"elapsed":14723,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jHPUQFI8xFlm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701271334988,"user_tz":-330,"elapsed":17771,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"f497ab0a-59db-45fd-f019-534bf2f9201f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.19,>=0.14 (from transformers)\n","  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","adapter-transformers 3.2.1 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.15.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.15.0\n"]}],"source":["# Transformers installation\n","! pip install transformers datasets\n","# To install from source instead of the last release, comment the command above and uncomment the following one.\n","# ! pip install git+https://github.com/huggingface/transformers.git"]},{"cell_type":"markdown","metadata":{"id":"oYoH8EjExFlq"},"source":["# Token classification"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","hide_input":true,"id":"8If9F4oaxFlr","outputId":"d86eb3e5-bc7f-46e2-a2bc-ec66bd75e523","colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"status":"ok","timestamp":1701269708463,"user_tz":-330,"elapsed":7,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n","  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wVHdVlPScxA?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"]},"metadata":{},"execution_count":2}],"source":["#@title\n","from IPython.display import HTML\n","\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wVHdVlPScxA?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"UPur3e3axFlt"},"source":["Token classification assigns a label to individual tokens in a sentence. One of the most common token classification tasks is Named Entity Recognition (NER). NER attempts to find a label for each entity in a sentence, such as a person, location, or organization.\n","\n","This guide will show you how to:\n","\n","1. Finetune [DistilBERT](https://huggingface.co/distilbert-base-uncased) on the [WNUT 17](https://huggingface.co/datasets/wnut_17) dataset to detect new entities.\n","2. Use your finetuned model for inference.\n","\n","<Tip>\n","The task illustrated in this tutorial is supported by the following model architectures:\n","\n","<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n","\n","[ALBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/albert), [BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bert), [BigBird](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/big_bird), [BioGpt](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/biogpt), [BLOOM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bloom), [CamemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/camembert), [CANINE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/canine), [ConvBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/convbert), [Data2VecText](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/data2vec-text), [DeBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta), [DeBERTa-v2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta-v2), [DistilBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/distilbert), [ELECTRA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/electra), [ERNIE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie), [ErnieM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie_m), [ESM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/esm), [FlauBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/flaubert), [FNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/fnet), [Funnel Transformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/funnel), [GPT-Sw3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt-sw3), [OpenAI GPT-2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt2), [GPTBigCode](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_bigcode), [GPT Neo](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neo), [GPT NeoX](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neox), [I-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ibert), [LayoutLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlm), [LayoutLMv2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv2), [LayoutLMv3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv3), [LiLT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/lilt), [Longformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/longformer), [LUKE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/luke), [MarkupLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/markuplm), [MEGA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mega), [Megatron-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/megatron-bert), [MobileBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mobilebert), [MPNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mpnet), [Nezha](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nezha), [Nyströmformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nystromformer), [QDQBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/qdqbert), [RemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/rembert), [RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta), [RoBERTa-PreLayerNorm](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta-prelayernorm), [RoCBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roc_bert), [RoFormer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roformer), [SqueezeBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/squeezebert), [XLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm), [XLM-RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta), [XLM-RoBERTa-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta-xl), [XLNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlnet), [X-MOD](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xmod), [YOSO](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/yoso)\n","\n","<!--End of the generated tip-->\n","\n","</Tip>\n","\n","Before you begin, make sure you have all the necessary libraries installed:\n","\n","```bash\n","pip install transformers datasets evaluate seqeval\n","```\n","\n","We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MG-ZKF8ExFlu","executionInfo":{"status":"ok","timestamp":1701269710023,"user_tz":-330,"elapsed":1565,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["301cbcc0bc76468d8176a476ab29d605","d465b475a6c64e8794b771d3feadf638","0abe4438786c4748a3bddac89a0e7663","003a41424c3545bba2e60d91dfb91c18","a0a16920eddd45359281a72fea2f6c20","5510acff04354b76997bac0e8c2374d3","de38393440404972a97b05c2a2d6758c","4445d7d1395f41f08e456b9aa5fb6e94","f008f4527e084aa1851d458fa3087696","1f9bb1da548d40228ac6dc4fc9daa58e","db6e35b45c57410b904a8bf8ab5ea290","ce360e38b9e943a2811aaebceed0072e","cd2e9e1050e84e329bf415a63547ec33","685399b0eeb444c6998ffe3d80f6b17f","31c00772eab340d8b2f65c6e95a0962d","5371557392a540cc9f75ab4139f79898","10b1588c0a2c471a9e5c6e95466f46f7","61ca03f013614229ba1e9a466ce21a2e","0790da897a0644a58932707414c8f668","bc2ea909789940ba811e80592c231d8a","ac4463f46807496c873708df89801e64","b65b56c3e4ee4343afc5be77fd279797","49ad12fe28a043c0881e5625de117596","1b49b7576ed847d7962c47b6eb3e8ad2","d14cd86d3cd64d6399bc4c8d4da04967","d88cc21d14ce488d9570aa2ce420a04c","d73ed6c0f625439fad9d405f1c516796","d3e1e9ff717043f5938a7aa8b5ae2d3e","b4b12df18a5b42cd90315af50bf2d3be","ce57e6fd724542528ba6a80f92cbc243","d973fdee06ee4910bdf235e12b6e1e0e","15c2218e403e48d1843b81979a58e840"]},"outputId":"57926d8c-ba59-4a54-a87d-ebbc6f84af70"},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"301cbcc0bc76468d8176a476ab29d605"}},"metadata":{}}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"QWlSU3nkxFlu"},"source":["## Load WNUT 17 dataset"]},{"cell_type":"markdown","metadata":{"id":"2n6r-LzcxFlu"},"source":["Start by loading the WNUT 17 dataset from the 🤗 Datasets library:"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmAgdGbexfem","executionInfo":{"status":"ok","timestamp":1701268187093,"user_tz":-330,"elapsed":19407,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"4b872956-31e2-4823-ce91-80ad8b3f6b0c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1y8ZBiDyxFlv","executionInfo":{"status":"ok","timestamp":1701271338473,"user_tz":-330,"elapsed":3495,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["from datasets import load_dataset, DatasetDict\n","\n","# wnut_orig = load_dataset(\"wnut_17\")\n","wnut = load_dataset(\"csv\", data_files=\"/content/drive/MyDrive/DL/DL project /clinical-adapter-1/Data/concept_assertion_relation_training_data/concept_data_final.csv\")"]},{"cell_type":"markdown","metadata":{"id":"hVIj3F_-xFlv"},"source":["Then take a look at an example:"]},{"cell_type":"code","source":["# from sklearn.model_selection import train_test_split\n","# train_data, test_data = train_test_split(wnut['train'], test_size=0.2, random_state=42)\n","# full_dataset = wnut['train']\n","# Split into train and test datasets\n","# train_data, test_data = full_dataset.train_test_split(test_size=0.2, seed=42)\n","\n","# # Create a DatasetDict object\n","# dataset_dict = DatasetDict({\"train\": train_data, \"test\": test_data})\n","\n","\n","# Split the original dataset into train, validation, and test sets\n","train_test = wnut['train'].train_test_split(test_size=0.1)  # 10% of the data for testing\n","\n","# Further split the training portion into train and validation\n","train_val = train_test['train'].train_test_split(test_size=0.1)  # 10% of the training data for validation\n","\n","# Create the DatasetDict object\n","wnut = DatasetDict({\n","    \"train\": train_val['train'],\n","    \"validation\": train_val['test'],\n","    \"test\": train_test['test']\n","})"],"metadata":{"id":"uBATzHLxSHJy","executionInfo":{"status":"ok","timestamp":1701271338474,"user_tz":-330,"elapsed":5,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# wnut_orig"],"metadata":{"id":"UtekSjTyx5P5","executionInfo":{"status":"ok","timestamp":1701271338474,"user_tz":-330,"elapsed":5,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["wnut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3aEDK8AyI1t","executionInfo":{"status":"ok","timestamp":1701271338474,"user_tz":-330,"elapsed":5,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"e6c683b2-b363-496a-c54c-0f405cbd4334"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags'],\n","        num_rows: 13214\n","    })\n","    validation: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags'],\n","        num_rows: 1469\n","    })\n","    test: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags'],\n","        num_rows: 1632\n","    })\n","})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"crdQSVmLxFlw","outputId":"1a0aeaa8-9df5-4e3d-83e3-19696cc7a7e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701271338474,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': \"['The', 'patient', 'recovered', 'well', 'status', 'post', 'these', 'two', 'procedures', '.']\",\n"," 'tags': \"['O', 'O', 'O', 'O', 'O', 'O', 'B-test', 'I-test', 'I-test', 'O']\",\n"," 'ner_tags': '[0, 0, 0, 0, 0, 0, 1, 2, 2, 0]'}"]},"metadata":{},"execution_count":6}],"source":["wnut[\"train\"][1]"]},{"cell_type":"markdown","metadata":{"id":"n73qvwU2xFlw"},"source":["Each number in `NER_TAG` represents an entity. Convert the numbers to their label names to find out what the entities are:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yHIimjwrxFlw","executionInfo":{"status":"ok","timestamp":1701271344138,"user_tz":-330,"elapsed":359,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["# wnut_orig = load_dataset(\"wnut_17\")\n","# label_list = wnut_orig[\"train\"].features[\"ner_tags\"].feature.names\n","# label_list\n","label_list = [\"O\", \"B-test\", \"I-test\", \"B-problem\", \"I-problem\", \"B-treatment\", \"I-treatment\"]\n","\n","#don't know how to do this for our data"]},{"cell_type":"markdown","metadata":{"id":"hSzxccj2xFlw"},"source":["The letter that prefixes each `ner_tag` indicates the token position of the entity:\n","\n","- `B-` indicates the beginning of an entity.\n","- `I-` indicates a token is contained inside the same entity (for example, the `State` token is a part of an entity like\n","  `Empire State Building`).\n","- `0` indicates the token doesn't correspond to any entity."]},{"cell_type":"markdown","metadata":{"id":"r9khO9p7xFlw"},"source":["## Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","hide_input":true,"id":"joD0YwPLxFlx","outputId":"c02ea258-62f2-4481-af2c-889d38623bcc","colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"status":"ok","timestamp":1701265723086,"user_tz":-330,"elapsed":6,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n","  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iY2AZYdZAr0?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"]},"metadata":{},"execution_count":11}],"source":["#@title\n","from IPython.display import HTML\n","\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iY2AZYdZAr0?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"sqw9Zx2jxFlx"},"source":["The next step is to load a DistilBERT tokenizer to preprocess the `tokens` field:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DqRmDeExxFlx","executionInfo":{"status":"error","timestamp":1701271361355,"user_tz":-330,"elapsed":12718,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"colab":{"base_uri":"https://localhost:8080/","height":546},"outputId":"b89b8f4b-a326-47c6-d1e4-7ddbb46d1310"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-744cfdbd9e8e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from tokenizers import SentencePieceBPETokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# sp_tokenizer = SentencePieceBPETokenizer(\"path/to/your/sentencepiece.model\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")   #bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emilyalsentzer/Bio_ClinicalBERT\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clinical BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# not required, check version only if installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Try: pip install transformers -U or pip install -e '.[dev]' if you're working with git main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0m_compare_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n","\u001b[0;31mImportError\u001b[0m: tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.15.0.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from transformers import AutoTokenizer, BertTokenizerFast\n","# from tokenizers import SentencePieceBPETokenizer\n","# sp_tokenizer = SentencePieceBPETokenizer(\"path/to/your/sentencepiece.model\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")   #bert\n","tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\") # clinical BERT\n","# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", tokenizer_class=sp_tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"K-yZL5LmxFlx"},"source":["As you saw in the example `tokens` field above, it looks like the input has already been tokenized. But the input actually hasn't been tokenized yet and you'll need to set `is_split_into_words=True` to tokenize the words into subwords. For example:"]},{"cell_type":"code","source":["\n","# example = wnut_orig[\"train\"][0]\n","# example"],"metadata":{"id":"pz2J3ur11abk","executionInfo":{"status":"ok","timestamp":1701270006168,"user_tz":-330,"elapsed":9,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# example"],"metadata":{"id":"13jbyZtt1YMx","executionInfo":{"status":"ok","timestamp":1701270006168,"user_tz":-330,"elapsed":9,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import ast"],"metadata":{"id":"hRO4EJlQ14d7","executionInfo":{"status":"ok","timestamp":1701270006168,"user_tz":-330,"elapsed":8,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sH3b3RPaxFlx","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["example = wnut[\"train\"][2]\n","tokenized_input = tokenizer(ast.literal_eval(example[\"tokens\"]), is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","tokens"]},{"cell_type":"markdown","metadata":{"id":"yn51JiYIxFlx"},"source":["However, this adds some special tokens `[CLS]` and `[SEP]` and the subword tokenization creates a mismatch between the input and labels. A single word corresponding to a single label may now be split into two subwords. You'll need to realign the tokens and labels by:\n","\n","1. Mapping all tokens to their corresponding word with the [`word_ids`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.BatchEncoding.word_ids) method.\n","2. Assigning the label `-100` to the special tokens `[CLS]` and `[SEP]` so they're ignored by the PyTorch loss function.\n","3. Only labeling the first token of a given word. Assign `-100` to other subtokens from the same word.\n","\n","Here is how you can create a function to realign the tokens and labels, and truncate sequences to be no longer than DistilBERT's maximum input length:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bBj4jaBxFly","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["def tokenize_and_align_labels(examples):\n","    examples_tokens = [ast.literal_eval(ele) for ele in examples[\"tokens\"]]\n","    tokenized_inputs = tokenizer(examples_tokens, truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    examples_ner= [ast.literal_eval(ele) for ele in examples[f\"ner_tags\"]]\n","    for i, label in enumerate(examples_ner):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"markdown","metadata":{"id":"ChRjsSJfxFly"},"source":["To apply the preprocessing function over the entire dataset, use 🤗 Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once:"]},{"cell_type":"code","source":["type(wnut)"],"metadata":{"id":"g0N2NyqVL2Xn","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guZTMLI4xFly","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["tokenized_wnut = wnut.map(tokenize_and_align_labels, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"TCNAF6qHxFly"},"source":["Now create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NslUWnuxFly","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"uRrVBrBlxFly"},"source":["## Evaluate"]},{"cell_type":"markdown","metadata":{"id":"_ekioePExFly"},"source":["Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [seqeval](https://huggingface.co/spaces/evaluate-metric/seqeval) framework (see the 🤗 Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric). Seqeval actually produces several scores: precision, recall, F1, and accuracy."]},{"cell_type":"code","source":["%pip install evaluate"],"metadata":{"id":"V59DRV7SNmPU","executionInfo":{"status":"aborted","timestamp":1701271361356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"id":"VglNz6AcRTA1","executionInfo":{"status":"aborted","timestamp":1701271361357,"user_tz":-330,"elapsed":5,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"BXUyMrNQxFly","executionInfo":{"status":"ok","timestamp":1701271363675,"user_tz":-330,"elapsed":2323,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["import evaluate\n","\n","seqeval = evaluate.load(\"seqeval\")"]},{"cell_type":"code","source":[],"metadata":{"id":"m_OI6_mmkErh","executionInfo":{"status":"ok","timestamp":1701270049186,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YPmPrOV7xFly"},"source":["Get the NER labels first, and then create a function that passes your true predictions and true labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the scores:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"BYzEcfyWxFlz","executionInfo":{"status":"error","timestamp":1701271365744,"user_tz":-330,"elapsed":660,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"colab":{"base_uri":"https://localhost:8080/","height":245},"outputId":"7e5f475c-d3a5-4845-a392-0c878090b3fc"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f05b3a5dcaa2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ast' is not defined"]}],"source":["\n","import numpy as np\n","\n","labels = [label_list[i] for i in ast.literal_eval(example[\"ner_tags\"])]\n","\n","\n","def compute_metrics(p):  #revisit\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"]},{"cell_type":"markdown","metadata":{"id":"XuSHTFbsxFlz"},"source":["Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."]},{"cell_type":"markdown","metadata":{"id":"9qR-gnYRxFlz"},"source":["## Train"]},{"cell_type":"markdown","metadata":{"id":"un7uKw1nxFlz"},"source":["Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BavI0PojxFlz","executionInfo":{"status":"ok","timestamp":1701271367386,"user_tz":-330,"elapsed":3,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[],"source":["# id2label = {\n","#     0: \"O\",\n","#     1: \"B-corporation\",\n","#     2: \"I-corporation\",\n","#     3: \"B-creative-work\",\n","#     4: \"I-creative-work\",\n","#     5: \"B-group\",\n","#     6: \"I-group\",\n","#     7: \"B-location\",\n","#     8: \"I-location\",\n","#     9: \"B-person\",\n","#     10: \"I-person\",\n","#     11: \"B-product\",\n","#     12: \"I-product\",\n","# }\n","# label2id = {\n","#     \"O\": 0,\n","#     \"B-corporation\": 1,\n","#     \"I-corporation\": 2,\n","#     \"B-creative-work\": 3,\n","#     \"I-creative-work\": 4,\n","#     \"B-group\": 5,\n","#     \"I-group\": 6,\n","#     \"B-location\": 7,\n","#     \"I-location\": 8,\n","#     \"B-person\": 9,\n","#     \"I-person\": 10,\n","#     \"B-product\": 11,\n","#     \"I-product\": 12,\n","# }\n","\n","id2label = {\n","    0: \"O\",\n","    1: \"B-test\",\n","    2: \"I-test\",\n","    3: \"B-problem\",\n","    4: \"I-problem\",\n","    5: \"B-treatment\",\n","    6: \"I-treatment\"\n","}\n","\n","label2id = {\n","    \"O\": 0,\n","    \"B-test\": 1,\n","    \"I-test\": 2,\n","    \"B-problem\": 3,\n","    \"I-problem\": 4,\n","    \"B-treatment\": 5,\n","    \"I-treatment\": 6\n","}"]},{"cell_type":"markdown","metadata":{"id":"qpFRoJUhxFlz"},"source":["<Tip>\n","\n","If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n","\n","</Tip>\n","\n","You're ready to start training your model now! Load DistilBERT with [AutoModelForTokenClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForTokenClassification) along with the number of expected labels, and the label mappings:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0VdD9kExFlz","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["2b9959d592c44efdb980330c5c794c66","40c0dc87fa70444fa2b0e46a8cf486e9","0c3ee0ee80124f769b6f383a3321e2f2","8b25985093cf4348afab1bc0c91edef3","43afc3c9199d4986b78fc85f9e726d3f","db11a56defd24137a1af8883cc928bd5","811dd744e52f45c6b3106903e46732a0","a712797fb34d497f97958f18eeee0c29","af4052225c754e66a0a1af5655c40b3a","75e7a43496fe46fa991fb2d988b273d8","550078efd2a04a0ea6bc9a1b652c5b53"]},"executionInfo":{"status":"ok","timestamp":1701265976473,"user_tz":-330,"elapsed":6605,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"cfca21b4-252a-41eb-be84-366f661eaa01"},"outputs":[{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b9959d592c44efdb980330c5c794c66"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n","\n","# model = AutoModelForTokenClassification.from_pretrained(\n","#     \"bert-base-uncased\", num_labels=7, id2label=id2label, label2id=label2id\n","# )   #bert\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=7, id2label=id2label, label2id=label2id\n",")\n","# model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n","# MODEL = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n","# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","# model = AutoModelForTokenClassification.from_pretrained(MODEL, num_labels=len(all_labels))\n","# model = AutoModelForTokenClassification.from_pretrained(MODEL, num_labels=7, id2label=id2label, label2id=label2id)"]},{"cell_type":"markdown","metadata":{"id":"O1oegC1QxFlz"},"source":["At this point, only three steps remain:\n","\n","1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the seqeval scores and save the training checkpoint.\n","2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n","3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."]},{"cell_type":"code","source":["# freeze all the parameters  #if full fine tuning, make it True\n","for param in model.parameters():\n","    param.requires_grad = True"],"metadata":{"id":"LD9f32qG46IX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install accelerate>=0.20.1"],"metadata":{"id":"2g2MzLz2PXup"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip show accelerate"],"metadata":{"id":"7MzxorXsP8ds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_wnut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCt2sFX5Q5BN","executionInfo":{"status":"ok","timestamp":1701266001851,"user_tz":-330,"elapsed":502,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"102d08e4-412d-44a2-9989-07d41de9e3bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 13214\n","    })\n","    validation: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 1469\n","    })\n","    test: Dataset({\n","        features: ['tokens', 'tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 1632\n","    })\n","})"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# learning_rate=2e-3"],"metadata":{"id":"5_okG7m7ippm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# learning_rate"],"metadata":{"id":"9RDyjlhAirFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e5IOnhExFl0","colab":{"base_uri":"https://localhost:8080/","height":395},"outputId":"eba78548-222a-4a93-f565-24aebe1e06f1"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7435' max='8260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7435/8260 23:04 < 02:33, 5.37 it/s, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.778200</td>\n","      <td>0.310879</td>\n","      <td>0.547938</td>\n","      <td>0.665989</td>\n","      <td>0.601223</td>\n","      <td>0.903608</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.248800</td>\n","      <td>0.201300</td>\n","      <td>0.679735</td>\n","      <td>0.763550</td>\n","      <td>0.719209</td>\n","      <td>0.933690</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.195100</td>\n","      <td>0.178329</td>\n","      <td>0.738007</td>\n","      <td>0.813008</td>\n","      <td>0.773694</td>\n","      <td>0.941500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.155900</td>\n","      <td>0.165702</td>\n","      <td>0.761194</td>\n","      <td>0.829268</td>\n","      <td>0.793774</td>\n","      <td>0.945838</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.134700</td>\n","      <td>0.162946</td>\n","      <td>0.773183</td>\n","      <td>0.836043</td>\n","      <td>0.803385</td>\n","      <td>0.947863</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.123300</td>\n","      <td>0.158891</td>\n","      <td>0.785218</td>\n","      <td>0.842141</td>\n","      <td>0.812684</td>\n","      <td>0.949237</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.115900</td>\n","      <td>0.161604</td>\n","      <td>0.774194</td>\n","      <td>0.845528</td>\n","      <td>0.808290</td>\n","      <td>0.947285</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.110900</td>\n","      <td>0.158333</td>\n","      <td>0.790742</td>\n","      <td>0.844851</td>\n","      <td>0.816901</td>\n","      <td>0.950322</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.102100</td>\n","      <td>0.158335</td>\n","      <td>0.792644</td>\n","      <td>0.846883</td>\n","      <td>0.818867</td>\n","      <td>0.950756</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["training_args = TrainingArguments(\n","    output_dir=\"my_awesome_wnut_model\",\n","    learning_rate=2e-6,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.002,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    push_to_hub=True,\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_wnut[\"train\"],\n","    eval_dataset=tokenized_wnut[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"NBUaCjWVi_MM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Access the training logs\n","train_logs = trainer.state.log_history\n","train_losses = []\n","eval_losses = []\n","\n","for log in train_logs:\n","    if 'loss' in log:\n","        train_losses.append(log['loss'])\n","    if 'eval_loss' in log:\n","        eval_losses.append(log['eval_loss'])\n","\n","# Plotting\n","plt.plot(train_losses, label=\"Training Loss\")\n","plt.plot(eval_losses, label=\"Evaluation Loss\")\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"YRFCzUqQiggP","executionInfo":{"status":"ok","timestamp":1700752918051,"user_tz":-330,"elapsed":646,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"bc9a6613-6779-49f4-88fa-5c0d6dd33ccb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"xARY3_5nikiL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KF_SoI5qxFl0"},"source":["Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SfwtsJGxFl4"},"outputs":[],"source":["# trainer.push_to_hub()"]},{"cell_type":"markdown","metadata":{"id":"UrHfkiECxFl4"},"source":["<Tip>\n","\n","For a more in-depth example of how to finetune a model for token classification, take a look at the corresponding\n","[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)\n","or [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb).\n","\n","</Tip>"]},{"cell_type":"markdown","metadata":{"id":"ykoVlQmCxFl4"},"source":["## Inference"]},{"cell_type":"markdown","metadata":{"id":"_smjO0d2xFl4"},"source":["Great, now that you've finetuned a model, you can use it for inference!\n","\n","Grab some text you'd like to run inference on:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWodXOAqxFl4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"j9kwhIaTxFl4"},"source":["The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for NER with your model, and pass your text to it:"]},{"cell_type":"code","source":["# ls /content/my_awesome_wnut_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuInSYi0dgPV","executionInfo":{"status":"ok","timestamp":1699388724708,"user_tz":-330,"elapsed":7,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"f02cf611-a6e1-46b5-cd45-6d99c8b30f1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcheckpoint-446\u001b[0m/  model.safetensors        tokenizer_config.json  vocab.txt\n","\u001b[01;34mcheckpoint-892\u001b[0m/  \u001b[01;34mruns\u001b[0m/                    tokenizer.json\n","config.json      special_tokens_map.json  training_args.bin\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIaFfg9RxFl5","outputId":"b2329295-297f-4340-e4d1-59f4e34d4a16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700752951428,"user_tz":-330,"elapsed":2664,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'entity': 'B-treatment', 'score': 0.9950128, 'index': 1, 'word': 'me', 'start': 0, 'end': 2} \n","\n","{'entity': 'B-treatment', 'score': 0.8203749, 'index': 2, 'word': '##cl', 'start': 2, 'end': 4} \n","\n","{'entity': 'B-treatment', 'score': 0.6742245, 'index': 3, 'word': '##iz', 'start': 4, 'end': 6} \n","\n","{'entity': 'I-treatment', 'score': 0.91906804, 'index': 4, 'word': '##ine', 'start': 6, 'end': 9} \n","\n"]}],"source":["# from transformers import pipeline\n","\n","# classifier = pipeline(\"ner\", model=\"stevhliu/my_awesome_wnut_model\")\n","# classifier(text)\n","\n","from transformers import pipeline\n","text = \"Meclizine 25 mg po bid .\"\n","classifier = pipeline(\"ner\", model=\"/content/my_awesome_wnut_model\")\n","result = classifier(text)\n","# print(result)\n","for r in result:\n","  print(r,\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"-Igl1ybgxFl5"},"source":["You can also manually replicate the results of the `pipeline` if you'd like:\n","\n","Tokenize the text and return PyTorch tensors:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JEAONulzxFl5"},"outputs":[],"source":["from transformers import AutoTokenizer\n","text = \"Meclizine 25 mg po bid .\"\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/my_awesome_wnut_model\")\n","inputs = tokenizer(text, return_tensors=\"pt\")"]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xm1S8_amgT2","executionInfo":{"status":"ok","timestamp":1700733260422,"user_tz":-330,"elapsed":6,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"1490a032-2039-4850-f915-ec629281e323"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  2033, 20464, 10993,  3170,  2423, 11460, 13433,  7226,  1012,\n","           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"ehT2lQF2xFl5"},"source":["Pass your inputs to the model and return the `logits`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GwWasj9xFl5"},"outputs":[],"source":["from transformers import AutoModelForTokenClassification\n","import torch\n","model = AutoModelForTokenClassification.from_pretrained(\"/content/my_awesome_wnut_model\")\n","with torch.no_grad():\n","    logits = model(**inputs).logits"]},{"cell_type":"markdown","metadata":{"id":"7PfaAZ_7xFl5"},"source":["Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PByishFxFl5","outputId":"cd44e8ed-bf97-4e25-fd0b-473c161dfe5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700733302606,"user_tz":-330,"elapsed":4,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O',\n"," 'B-treatment',\n"," 'I-treatment',\n"," 'I-treatment',\n"," 'I-treatment',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O']"]},"metadata":{},"execution_count":34}],"source":["predictions = torch.argmax(logits, dim=2)\n","predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n","predicted_token_class"]},{"cell_type":"code","source":["# print(test_predictions[0])"],"metadata":{"id":"d-VHebWNfmFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_predictions = trainer.predict(tokenized_wnut[\"test\"])\n","metrics = compute_metrics([test_predictions[0],test_predictions[1]])\n","print(metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"SqyMwXabedhz","executionInfo":{"status":"ok","timestamp":1700752983886,"user_tz":-330,"elapsed":6574,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"d2eb4107-95b3-40e2-bd58-7bc5b2fbbb95"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'precision': 0.770962296004502, 'recall': 0.8282950423216445, 'f1': 0.7986009909647334, 'accuracy': 0.9454003522557919}\n"]}]},{"cell_type":"code","source":["def combine_subwords(text, entities):\n","\n","    curr_word = entities[0]['word']\n","    new_entities = [entities[0]['entity']]\n","    word_list=[]\n","\n","    for i in range(1, len(entities)):\n","      if entities[i]['word'][0:2] == '##':\n","        curr_word += str(entities[i]['word'][2:])\n","      else:\n","        if curr_word:\n","          word_list.append(curr_word)\n","        curr_word=\"\"\n","        word_list.append(entities[i]['word'])\n","        new_entities.append(entities[i]['entity'])\n","\n","    return word_list, new_entities\n","\n","\n","# Example usage\n","text = \"Meclizine 25 mg po bid .\"\n","entities = [\n","    {'entity': 'B-treatment', 'score': 0.999782, 'index': 1, 'word': 'me', 'start': 0, 'end': 2},\n","    {'entity': 'I-treatment', 'score': 0.99756914, 'index': 2, 'word': '##clizine', 'start': 2, 'end': 9},\n","    {'entity': 'I-treatment', 'score': 0.999782, 'index': 1, 'word': 'dust', 'start': 0, 'end': 2},\n","    {'entity': 'O', 'word': '25', 'start': 10, 'end': 12},\n","    {'entity': 'O', 'word': 'mg', 'start': 13, 'end': 15},\n","    {'entity': 'O', 'word': 'po', 'start': 16, 'end': 18},\n","    {'entity': 'O', 'word': 'bid', 'start': 19, 'end': 22},\n","    {'entity': 'O', 'word': '.', 'start': 23, 'end': 24}\n","]\n","\n","reconstructed_text, combined_entities = combine_subwords(text, entities)\n","print(\"Reconstructed Text:\", reconstructed_text)\n","print(\"Combined Entities:\", combined_entities)\n"],"metadata":{"id":"0xoJ5x8sPM7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701269090043,"user_tz":-330,"elapsed":3,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"bd463467-fb57-442b-d1bd-ad681b6772a2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Reconstructed Text: ['meclizine', 'dust', '25', 'mg', 'po', 'bid', '.']\n","Combined Entities: ['B-treatment', 'I-treatment', 'O', 'O', 'O', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["Adapters"],"metadata":{"id":"GOLgzCjknNOu"}},{"cell_type":"code","source":["!pip install adapters"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdh20De2qwQ9","executionInfo":{"status":"ok","timestamp":1701272211355,"user_tz":-330,"elapsed":18413,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"4fe01aca-5200-40df-f3b7-cd8c7bc026bf"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting adapters\n","  Downloading adapters-0.1.0-py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (from adapters) (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->adapters) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->adapters) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->adapters) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2->adapters) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2->adapters) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2->adapters) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2->adapters) (2023.7.22)\n","Installing collected packages: adapters\n","Successfully installed adapters-0.1.0\n"]}]},{"cell_type":"code","source":["pip install tokenizers==0.11.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiGZvHHwrmlS","executionInfo":{"status":"ok","timestamp":1701271628606,"user_tz":-330,"elapsed":25225,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"9838ee9a-12e0-43c5-b408-1368c04c5919"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tokenizers==0.11.0\n","  Downloading tokenizers-0.11.0.tar.gz (216 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: tokenizers\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n","\u001b[0mFailed to build tokenizers\n","\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from transformers import BertConfig, AutoAdapterModel,AutoTokenizer\n","\n","tokenizer_clinical_bio  = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",model_max_length=150)\n","model_clinical_adapter = AutoAdapterModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=7, id2label=id2label, label2id=label2id)\n","\n","model_clinical_adapter.add_adapter(\"i2b2-ner\")\n","model_clinical_adapter.train_adapter(\"i2b2-ner\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546},"id":"D9POMv_LgmCr","executionInfo":{"status":"error","timestamp":1701272217219,"user_tz":-330,"elapsed":415,"user":{"displayName":"Niharika Kumari","userId":"04618416380309212955"}},"outputId":"75c1d29d-2df6-4036-eadd-b353f69d41e1"},"execution_count":17,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ab769d335df3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoAdapterModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer_clinical_bio\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emilyalsentzer/Bio_ClinicalBERT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_clinical_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoAdapterModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emilyalsentzer/Bio_ClinicalBERT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel2id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# not required, check version only if installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Try: pip install transformers -U or pip install -e '.[dev]' if you're working with git main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0m_compare_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n","\u001b[0;31mImportError\u001b[0m: tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.15.0.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import numpy as np\n","from transformers import TrainingArguments, AdapterTrainer, EvalPrediction\n","\n","adaptraining_args = TrainingArguments(\n","    learning_rate=1e-4,\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=1,\n","    output_dir=\"./clinical_bert_adapter\",\n","    overwrite_output_dir=True,\n","    # The next line is important to ensure the dataset labels are properly passed to the model\n","   # remove_unused_columns=False,\n",")\n","\n","\n","adaptrainer = AdapterTrainer(\n","    model=model_clinical_adapter,\n","    args=adaptraining_args,\n","    train_dataset=tokenized_wnut[\"train\"],\n","    eval_dataset=tokenized_wnut[\"validation\"],\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"hqNzpQHQp6xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adaptrainer.train()"],"metadata":{"id":"RUAFgichp8sQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_clinical_adapter.save_all_adapters(\"./clinical_bert_adapter\")"],"metadata":{"id":"QTFXGdDvp-UM"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/token_classification.ipynb","timestamp":1699108663859}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b9959d592c44efdb980330c5c794c66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40c0dc87fa70444fa2b0e46a8cf486e9","IPY_MODEL_0c3ee0ee80124f769b6f383a3321e2f2","IPY_MODEL_8b25985093cf4348afab1bc0c91edef3"],"layout":"IPY_MODEL_43afc3c9199d4986b78fc85f9e726d3f"}},"40c0dc87fa70444fa2b0e46a8cf486e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db11a56defd24137a1af8883cc928bd5","placeholder":"​","style":"IPY_MODEL_811dd744e52f45c6b3106903e46732a0","value":"pytorch_model.bin: 100%"}},"0c3ee0ee80124f769b6f383a3321e2f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a712797fb34d497f97958f18eeee0c29","max":435778770,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af4052225c754e66a0a1af5655c40b3a","value":435778770}},"8b25985093cf4348afab1bc0c91edef3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75e7a43496fe46fa991fb2d988b273d8","placeholder":"​","style":"IPY_MODEL_550078efd2a04a0ea6bc9a1b652c5b53","value":" 436M/436M [00:01&lt;00:00, 257MB/s]"}},"43afc3c9199d4986b78fc85f9e726d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db11a56defd24137a1af8883cc928bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"811dd744e52f45c6b3106903e46732a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a712797fb34d497f97958f18eeee0c29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af4052225c754e66a0a1af5655c40b3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75e7a43496fe46fa991fb2d988b273d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"550078efd2a04a0ea6bc9a1b652c5b53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"301cbcc0bc76468d8176a476ab29d605":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ac4463f46807496c873708df89801e64","IPY_MODEL_b65b56c3e4ee4343afc5be77fd279797","IPY_MODEL_49ad12fe28a043c0881e5625de117596","IPY_MODEL_1b49b7576ed847d7962c47b6eb3e8ad2"],"layout":"IPY_MODEL_de38393440404972a97b05c2a2d6758c"}},"d465b475a6c64e8794b771d3feadf638":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4445d7d1395f41f08e456b9aa5fb6e94","placeholder":"​","style":"IPY_MODEL_f008f4527e084aa1851d458fa3087696","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"0abe4438786c4748a3bddac89a0e7663":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_1f9bb1da548d40228ac6dc4fc9daa58e","placeholder":"​","style":"IPY_MODEL_db6e35b45c57410b904a8bf8ab5ea290","value":""}},"003a41424c3545bba2e60d91dfb91c18":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_ce360e38b9e943a2811aaebceed0072e","style":"IPY_MODEL_cd2e9e1050e84e329bf415a63547ec33","value":true}},"a0a16920eddd45359281a72fea2f6c20":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_685399b0eeb444c6998ffe3d80f6b17f","style":"IPY_MODEL_31c00772eab340d8b2f65c6e95a0962d","tooltip":""}},"5510acff04354b76997bac0e8c2374d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5371557392a540cc9f75ab4139f79898","placeholder":"​","style":"IPY_MODEL_10b1588c0a2c471a9e5c6e95466f46f7","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"de38393440404972a97b05c2a2d6758c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"4445d7d1395f41f08e456b9aa5fb6e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f008f4527e084aa1851d458fa3087696":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9bb1da548d40228ac6dc4fc9daa58e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db6e35b45c57410b904a8bf8ab5ea290":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce360e38b9e943a2811aaebceed0072e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2e9e1050e84e329bf415a63547ec33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"685399b0eeb444c6998ffe3d80f6b17f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c00772eab340d8b2f65c6e95a0962d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"5371557392a540cc9f75ab4139f79898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10b1588c0a2c471a9e5c6e95466f46f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61ca03f013614229ba1e9a466ce21a2e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0790da897a0644a58932707414c8f668","placeholder":"​","style":"IPY_MODEL_bc2ea909789940ba811e80592c231d8a","value":"Connecting..."}},"0790da897a0644a58932707414c8f668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc2ea909789940ba811e80592c231d8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac4463f46807496c873708df89801e64":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14cd86d3cd64d6399bc4c8d4da04967","placeholder":"​","style":"IPY_MODEL_d88cc21d14ce488d9570aa2ce420a04c","value":"Token is valid (permission: write)."}},"b65b56c3e4ee4343afc5be77fd279797":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d73ed6c0f625439fad9d405f1c516796","placeholder":"​","style":"IPY_MODEL_d3e1e9ff717043f5938a7aa8b5ae2d3e","value":"Your token has been saved in your configured git credential helpers (store)."}},"49ad12fe28a043c0881e5625de117596":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4b12df18a5b42cd90315af50bf2d3be","placeholder":"​","style":"IPY_MODEL_ce57e6fd724542528ba6a80f92cbc243","value":"Your token has been saved to /root/.cache/huggingface/token"}},"1b49b7576ed847d7962c47b6eb3e8ad2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d973fdee06ee4910bdf235e12b6e1e0e","placeholder":"​","style":"IPY_MODEL_15c2218e403e48d1843b81979a58e840","value":"Login successful"}},"d14cd86d3cd64d6399bc4c8d4da04967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d88cc21d14ce488d9570aa2ce420a04c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d73ed6c0f625439fad9d405f1c516796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3e1e9ff717043f5938a7aa8b5ae2d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4b12df18a5b42cd90315af50bf2d3be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce57e6fd724542528ba6a80f92cbc243":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d973fdee06ee4910bdf235e12b6e1e0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c2218e403e48d1843b81979a58e840":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}