{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ClinicalBERT for clinical assertion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post, we will show how to fine-tune a bert language model for a downstream task: clinical assertion detection. We are going to leverage the Hugging Face transformer library and the model hub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show how  :\n",
    "\n",
    "1. Load and prepare the data for assertion dectection\n",
    "\n",
    "2. Fine-tune an auto-encoding language model such as Clinical BERT\n",
    "\n",
    "3. Evaluate and run Inference with the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Background and Context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical assertion dectection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is based on the paper \"Assertion Detection in Clinical Notes: Medical Language Models to the Rescue?\" , using Language model for assertion detection. Assertion detection is the task to identify the assertion of an entity based on textual cues in unstructured text. In other words we want to classify the assertions made on given medical concepts as being :\n",
    "* present\n",
    "* absent\n",
    "* possible in the patient\n",
    "* conditionally present in the patient under certain circumstances\n",
    "* hypothtically present in the patient at some future point\n",
    "* mentioned in the patient report but associated with somenone else\n",
    "\n",
    "For example given the text \"The patient recovered during the night and now denies any shortness of breath.\", the model should identify that the entity: shortness of breath is absent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we use The 2010 i2b2/VA Workshop on Natural Language Processing Challenges for Clinical Records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; \n",
    "and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. These are be available to the research community from [i2b2](https://i2b2.org/NLP/DataSets) portal under data use agreements. For more information please consult the paper [2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text](https://academic.oup.com/jamia/article/18/5/552/830538)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to request access, download and extract  the data needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the Pytorch and HuggingFace library, an run the experiemnt on a Google Colab. You will also need to install spacy and the biomedical pretrained model  **en_ner_bc5cdr_md** a spaCy NER model trained on the BC5CDR corpus. The model en_ner_bc5cdr_md was trained for DISEASE and CHEMICAL entity recognition. To install all the dependencies run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all the libraries and dependencies\n",
    "#%pip install -r requirements.txt\n",
    "#python=3.8\n",
    "# conda install matplotlib numpy scikit-learn\n",
    "# conda install pandas\n",
    "# pip install spacy\n",
    "# pip install scispacy ? gave error ignored\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
    "# conda install pytorch torchvision -c pytorch\n",
    "# pip install ipykernel\n",
    "# pip install transformers\n",
    "# pip install datasets\n",
    "# pip install evaluate\n",
    "# pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the assertion classification data from i2b2, which consist of XXXXX records of discharge summary notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\Documents\\GitHub\\clinical-adapter\\Data/concept_assertion_relation_training_data\\beth\\ast\n",
      "C:\\Users\\kcaro\\Documents\\GitHub\\clinical-adapter\\Data/concept_assertion_relation_training_data\\beth\\txt\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd  = os.getcwd()\n",
    "labels_path = os.path.join(cwd,\"Data/concept_assertion_relation_training_data\",\"beth\",\"ast\")\n",
    "data_path = os.path.join(cwd,\"Data/concept_assertion_relation_training_data\",\"beth\",\"txt\")\n",
    "\n",
    "print(labels_path)\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the files names\n",
    "records = [i for i in range(13, 39)]\n",
    "records = records + [i for i in range(45, 57)]\n",
    "records = records + [58,59]\n",
    "records = records + [i for i in range(65, 71)]\n",
    "records = records + [73,74]\n",
    "records = records + [i for i in range(81, 85)]\n",
    "records = records + [i for i in range(105,109)]\n",
    "records = records + [i for i in range(121,125)]\n",
    "records = records + [i for i in range(140,145)]\n",
    "records = records + [i for i in range(175,180)]\n",
    "records_files = [f\"record-{i}.txt\" for i in records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function which loops in text files list and read each file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_notes(records_files):\n",
    "    # reading the data files in a list\n",
    "    content_records = []\n",
    "    for record in records_files:\n",
    "        _file = os.path.join(data_path,record)\n",
    "        with open(_file) as f:\n",
    "            content = f.read()\n",
    "            #lines = content.split(\"\\n\")\n",
    "            content_records.append((record[:-4],content))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return content_records\n",
    "\n",
    "content_records = load_clinical_notes(records_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split each note into sentences using spacy biomedical pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\miniconda3\\envs\\clinical-adapter\\lib\\site-packages\\spacy\\util.py:887: UserWarning: [W095] Model 'en_ner_bc5cdr_md' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import en_ner_bc5cdr_md\n",
    "import spacy\n",
    "\n",
    "def split_note_sentences(content_records):\n",
    "    # load spacy\n",
    "    nlp1 = spacy.load(\"en_ner_bc5cdr_md\",disable = ['parser'])\n",
    "    nlp1.add_pipe('sentencizer')\n",
    "\n",
    "    # transform the data into a list of sentences\n",
    "    docs = [(r,nlp1(text)) for r,text in content_records]\n",
    "    data = []\n",
    "    for r,doc in docs:\n",
    "        for s in doc.sents:\n",
    "            sentence = str.strip(str(s))\n",
    "            sentence = sentence.replace(\"\\n\",\" \")\n",
    "            data.append((r,sentence))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = split_note_sentences(content_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load and process the labels. They are provided as ast files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>assertion</th>\n",
       "      <th>label</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>coronary artery disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>left arm phlebitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record-13</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>further episodes of afib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>mildly thickened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>seasonal allergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>his embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>record-179</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>discoid lateral meniscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          record assertion    label                        entity\n",
       "0      record-13   present  problem       coronary artery disease\n",
       "1      record-13   present  problem  burst of atrial fibrillation\n",
       "2      record-13   present  problem            left arm phlebitis\n",
       "3      record-13    absent  problem      further episodes of afib\n",
       "4      record-13   present  problem              mildly thickened\n",
       "...          ...       ...      ...                           ...\n",
       "4107  record-179   present  problem            seasonal allergies\n",
       "4108  record-179   present  problem                   his embolus\n",
       "4109  record-179    absent  problem                         cough\n",
       "4110  record-179   present  problem      discoid lateral meniscus\n",
       "4111  record-179   present  problem             pulmonary embolus\n",
       "\n",
       "[4112 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "def load_notes_labels(records):\n",
    "\n",
    "    records_files_ast = [f\"record-{i}.ast\" for i in records]\n",
    "    \n",
    "    # load labels in a list\n",
    "    labels_records = []\n",
    "    for record in records_files_ast:\n",
    "        _file = os.path.join(labels_path,record)\n",
    "        #print(_file)\n",
    "        with open(_file) as f:\n",
    "            content = f.readlines()\n",
    "            file_data = []\n",
    "            for line in content:\n",
    "                ast = line.strip().split('||')\n",
    "                line_entity = []\n",
    "\n",
    "                assertion = ast[2].split('=')\n",
    "                entity_label = ast[1].split(\"=\")\n",
    "        \n",
    "                entity_text = re.findall('\"([^\"]*)\"', ast[0])\n",
    "\n",
    "                line_entity.append(record[:-4])\n",
    "                line_entity.append(assertion[1].replace('\"',''))\n",
    "                line_entity.append(entity_label[1].replace('\"',''))\n",
    "                line_entity.append(entity_text[0])\n",
    "                file_data.append(line_entity)\n",
    "        labels_records.append(file_data)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return labels_records\n",
    "\n",
    "labels_records  = load_notes_labels(records)\n",
    "\n",
    "# labels in a dataframe\n",
    "data_labels = [line for f in labels_records for line in f]\n",
    "df_data_labels = pd.DataFrame(data_labels,columns=['record','assertion','label','entity'])\n",
    "\n",
    "df_data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Annotate text for clinical assertion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing the data we need to annotate each entity in our training data between the token '[entity]' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # remove all non-ASCII characters:\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) \n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to map the data with the labels. We do so by using the record id and searching the entity name in the text to do the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linking_train_labels_data(data,df_data_labels):\n",
    "    new_data = []\n",
    "    for r , sent in data:\n",
    "        for index,row in df_data_labels.loc[df_data_labels['record'] == r,['entity','assertion']].iterrows():\n",
    "            entity = clean_text(row['entity'])\n",
    "            sentence = clean_text(sent)\n",
    "            #print(entity,sent)\n",
    "            try:\n",
    "                if re.search(r'\\b' + str(entity) + r'\\b', str(sentence)):\n",
    "                    new_data.append((r,entity,sentence,row['assertion']))\n",
    "            except:\n",
    "                print(r)\n",
    "                print(\"entity:\",str(entity))\n",
    "                print(\"****\")\n",
    "    return new_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = linking_train_labels_data(data,df_data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can annotate each sentence with the token [entity]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_data(new_data):\n",
    "    processed_data = []\n",
    "    for r,entity,text,label in new_data:\n",
    "        #print(text)\n",
    "        match = re.search(r'\\b' + entity + r'\\b',text)\n",
    "\n",
    "        res = list(text)\n",
    "        res.insert(match.start(), '[entity] ')\n",
    "        res.insert(match.end()+1, ' [entity]')\n",
    "        res = ''.join(res)\n",
    "        processed_data.append((r,entity,res,label))  \n",
    "\n",
    "    return processed_data\n",
    "\n",
    "processed_data =  annotate_data(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>assertion</th>\n",
       "      <th>label</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>coronary artery disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>left arm phlebitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record-13</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>further episodes of afib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>mildly thickened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>seasonal allergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>his embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>record-179</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>discoid lateral meniscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          record assertion    label                        entity\n",
       "0      record-13   present  problem       coronary artery disease\n",
       "1      record-13   present  problem  burst of atrial fibrillation\n",
       "2      record-13   present  problem            left arm phlebitis\n",
       "3      record-13    absent  problem      further episodes of afib\n",
       "4      record-13   present  problem              mildly thickened\n",
       "...          ...       ...      ...                           ...\n",
       "4107  record-179   present  problem            seasonal allergies\n",
       "4108  record-179   present  problem                   his embolus\n",
       "4109  record-179    absent  problem                         cough\n",
       "4110  record-179   present  problem      discoid lateral meniscus\n",
       "4111  record-179   present  problem             pulmonary embolus\n",
       "\n",
       "[4112 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>assertion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left arm phlebitis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>further episodes of afib</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mildly thickened</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe 3 vessel disease</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mildly dilated</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>carpal tunnel syndrome</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>increased pain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>any weight gain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>any fever greater than 101</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>surgical incision</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incisions</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abnormal ett</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>redness</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>drainage</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>varicosities</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worsening shortness of breath.</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>edema</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>known allergies</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>simple atheroma in the descending thoracic aorta</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carpal tunnel syndrome</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bell's palsy</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mild inferior wall hypokinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aortic regurgitation</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aortic valve stenosis</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>shortness of breath</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pneumothorax</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>left lower lobe atelectasis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>trivial mitral regurgitation</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mild postoperative widening of the cardiomedia...</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mi</td>\n",
       "      <td>associated_with_someone_else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>w/r/r</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thinning of the mid to distal inferior septum</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>nc/at</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>akinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>carotid bruits</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mildly depressed</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dyskinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c/r/m/g</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wounds</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>infection</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hoh</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>jvd</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nt/nd</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nad</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               entity  \\\n",
       "0                             coronary artery disease   \n",
       "1                        burst of atrial fibrillation   \n",
       "2                                  left arm phlebitis   \n",
       "3                            further episodes of afib   \n",
       "4                                    mildly thickened   \n",
       "5                             severe 3 vessel disease   \n",
       "6                                      mildly dilated   \n",
       "7                                        hypertension   \n",
       "8                              carpal tunnel syndrome   \n",
       "9                                      increased pain   \n",
       "10                                    any weight gain   \n",
       "11                         any fever greater than 101   \n",
       "12                                  surgical incision   \n",
       "13                                          incisions   \n",
       "14                                       abnormal ett   \n",
       "15                                               pain   \n",
       "16                                            redness   \n",
       "17                                           drainage   \n",
       "18                                          arthritis   \n",
       "19                                       varicosities   \n",
       "20                     worsening shortness of breath.   \n",
       "21                                     hyperlipidemia   \n",
       "22                                              edema   \n",
       "23                                       hypertension   \n",
       "24                                    known allergies   \n",
       "25   simple atheroma in the descending thoracic aorta   \n",
       "26                             carpal tunnel syndrome   \n",
       "27                                       bell's palsy   \n",
       "28                     mild inferior wall hypokinesis   \n",
       "29                               aortic regurgitation   \n",
       "30                              aortic valve stenosis   \n",
       "31                                shortness of breath   \n",
       "32                                       pneumothorax   \n",
       "33                        left lower lobe atelectasis   \n",
       "34                       trivial mitral regurgitation   \n",
       "35  mild postoperative widening of the cardiomedia...   \n",
       "36                                                 mi   \n",
       "37                                              w/r/r   \n",
       "38      thinning of the mid to distal inferior septum   \n",
       "39                                              nc/at   \n",
       "40                                           akinesis   \n",
       "41                                     carotid bruits   \n",
       "42                                   mildly depressed   \n",
       "43                                         dyskinesis   \n",
       "44                                            c/r/m/g   \n",
       "45                                             wounds   \n",
       "46                                          infection   \n",
       "47                                                hoh   \n",
       "48                                          arthritis   \n",
       "49                                     hyperlipidemia   \n",
       "50                                                jvd   \n",
       "51                                              nt/nd   \n",
       "52                                                nad   \n",
       "\n",
       "                       assertion  \n",
       "0                        present  \n",
       "1                        present  \n",
       "2                        present  \n",
       "3                         absent  \n",
       "4                        present  \n",
       "5                        present  \n",
       "6                        present  \n",
       "7                        present  \n",
       "8                        present  \n",
       "9                   hypothetical  \n",
       "10                  hypothetical  \n",
       "11                  hypothetical  \n",
       "12                       present  \n",
       "13                       present  \n",
       "14                       present  \n",
       "15                  hypothetical  \n",
       "16                  hypothetical  \n",
       "17                  hypothetical  \n",
       "18                       present  \n",
       "19                        absent  \n",
       "20                       present  \n",
       "21                       present  \n",
       "22                        absent  \n",
       "23                       present  \n",
       "24                        absent  \n",
       "25                       present  \n",
       "26                       present  \n",
       "27                       present  \n",
       "28                       present  \n",
       "29                        absent  \n",
       "30                        absent  \n",
       "31                       present  \n",
       "32                        absent  \n",
       "33                       present  \n",
       "34                       present  \n",
       "35                       present  \n",
       "36  associated_with_someone_else  \n",
       "37                        absent  \n",
       "38                       present  \n",
       "39                        absent  \n",
       "40                       present  \n",
       "41                        absent  \n",
       "42                       present  \n",
       "43                       present  \n",
       "44                        absent  \n",
       "45                       present  \n",
       "46                  hypothetical  \n",
       "47                       present  \n",
       "48                       present  \n",
       "49                       present  \n",
       "50                        absent  \n",
       "51                        absent  \n",
       "52                        absent  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_labels.loc[df_data_labels['record'] =='record-13' ,['entity','assertion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('record-13',\n",
       " 'known allergies',\n",
       " 'admission date 2018 10 25 discharge date 2018 10 31 date of birth 1951 06 15 sex m service cardiothoracic allergies patient recorded as having no [entity] known allergies [entity] to drugs attending michael d christensen m d chief complaint shortness of breath major surgical or invasive procedure coronary artery bypass graft x3 left internal mammary left anterior descending saphaneous vein graft obtuse marginal saphaneous vein graft posterior descending artery 2018 10 25 history of present illness 67 y o male with worsening shortness of breath',\n",
       " 'absent')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('record-13',\n",
    " 'known allergies',\n",
    " 'admission date 2018 10 25 discharge date 2018 10 31 date of birth 1951 06 15 sex m service cardiothoracic allergies patient recorded as having no [entity] known allergies [entity] to drugs attending michael d christensen m d chief complaint shortness of breath major surgical or invasive procedure coronary artery bypass graft x3 left internal mammary left anterior descending saphaneous vein graft obtuse marginal saphaneous vein graft posterior descending artery 2018 10 25 history of present illness 67 y o male with worsening shortness of breath',\n",
    " 'absent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally , we create a dataframe where for our example we only keep 3 assertions labels : present , absent and possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>had [entity] abnormal ett [entity] and referre...</td>\n",
       "      <td>present</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cath revealed [entity] severe 3 vessel disease...</td>\n",
       "      <td>present</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>the mri of your knee showed [entity] a menisca...</td>\n",
       "      <td>present</td>\n",
       "      <td>6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>the mri of your knee showed a [entity] menisca...</td>\n",
       "      <td>possible</td>\n",
       "      <td>6534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence     label   idx\n",
       "0     admission date 2018 10 25 discharge date 2018 ...   present     0\n",
       "1     admission date 2018 10 25 discharge date 2018 ...    absent     1\n",
       "2     admission date 2018 10 25 discharge date 2018 ...   present     2\n",
       "3     had [entity] abnormal ett [entity] and referre...   present     3\n",
       "4     cath revealed [entity] severe 3 vessel disease...   present     4\n",
       "...                                                 ...       ...   ...\n",
       "6530  medications on admission claritin prn flonase ...   present  6530\n",
       "6531  medications on admission claritin prn flonase ...   present  6531\n",
       "6532  medications on admission claritin prn flonase ...   present  6532\n",
       "6533  the mri of your knee showed [entity] a menisca...   present  6533\n",
       "6534  the mri of your knee showed a [entity] menisca...  possible  6534\n",
       "\n",
       "[6072 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data = [{'sentence':text , 'label':label,'idx':idx} for idx,(r, entity, text,label) in enumerate(processed_data)]\n",
    "\n",
    "df_i2b2 = pd.DataFrame(prepare_data)\n",
    "df_i2b2 = df_i2b2[(df_i2b2.label=='present') | (df_i2b2.label=='absent') | (df_i2b2.label=='possible') ].copy()\n",
    "df_i2b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    admission date 2018 10 25 discharge date 2018 ...\n",
       "label                                                 present\n",
       "idx                                                         0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i2b2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Splitting the data and create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sklearn to split the data into train, validation and test set. We have 80% for training, 10% for testing and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (873,) y_train shape : (873,)\n",
      "X_valid shape (219,) y_valid shape : (219,)\n",
      "X_test shape (122,) y_test shape : (122,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_i2b2 = df_i2b2.sample(frac=0.2).copy()\n",
    "\n",
    "X = df_i2b2['sentence']\n",
    "y = df_i2b2['label']\n",
    "\n",
    "X_train_valid,X_test,y_train_valid, y_test= train_test_split(X,y,test_size=0.1,stratify=y,random_state=42)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_valid,y_train_valid,train_size=0.8,random_state=42,stratify=y_train_valid)\n",
    "\n",
    "print(f\"X_train shape {X_train.shape} y_train shape : {y_train.shape}\")\n",
    "print(f\"X_valid shape {X_valid.shape} y_valid shape : {y_valid.shape}\")\n",
    "print(f\"X_test shape {X_test.shape} y_test shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(873,) (873,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['present', 'present', 'absent', ..., 'present', 'present',\n",
       "        'absent'],\n",
       "       ['[entity] hypertension [entity]',\n",
       "        'admission date 2015 03 26 discharge date 2015 03 30 date of birth 1967 03 08 sex f service medicine allergies morphine histamine h2 inhibitors heparin agents attending terry t trott m d chief complaint [entity] increasing abdominal girth [entity] major surgical or invasive procedure 4u ffp paracentesis history of present illness 47 female with h o hcv cirrhosis compocated by encephalopathy ascites and h o portal vein thrombosis right anterior portal vein and portalcaval shunt reversed flow in main portal vein presents from liver clinic with increasing abdominal girth',\n",
       "        'status post ileostomy without evidence of [entity] small bowel obstruction [entity]',\n",
       "        ...,\n",
       "        'at the time of transfer he was initially admitted to the cmi service after undergoing cardiac catheterization which revealed [entity] a long lad lesion [entity] that was angioplastied without stent placement and a total occlusion of the rca with collaterals',\n",
       "        '[entity] nicholas seizures [entity] no loc no head or neck trauma',\n",
       "        'abdomen bowel sounds positive soft [entity] non tender [entity] non distended']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(X_train.shape,y_train.shape)\n",
    "np.vstack((y_train,X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use sklearn to encode our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Labels .....\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Encoding Labels .....\")\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train_encode = np.asarray(encoder.transform(y_train))\n",
    "y_valid_encode = np.asarray(encoder.transform(y_valid))\n",
    "y_test_encode = np.asarray(encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195                       [entity] hypertension [entity]\n",
       "1567    admission date 2015 03 26 discharge date 2015 ...\n",
       "1026    status post ileostomy without evidence of [ent...\n",
       "5516    it was unchanged in comparison to 2017 08 14 w...\n",
       "2452    carduac enzymes mildly elevated felt 02 08 [en...\n",
       "                              ...                        \n",
       "1854    patient denies [entity] cp [entity] sob light ...\n",
       "2684    history of present illness the patient is a 64...\n",
       "4070    at the time of transfer he was initially admit...\n",
       "1852    [entity] nicholas seizures [entity] no loc no ...\n",
       "2608    abdomen bowel sounds positive soft [entity] no...\n",
       "Name: sentence, Length: 873, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\miniconda3\\envs\\clinical-adapter\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               sentence  label\n",
      "4195                     [entity] hypertension [entity]      2\n",
      "1567  admission date 2015 03 26 discharge date 2015 ...      2\n",
      "1026  status post ileostomy without evidence of [ent...      0\n",
      "5516  it was unchanged in comparison to 2017 08 14 w...      2\n",
      "2452  carduac enzymes mildly elevated felt 02 08 [en...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(X_train)\n",
    "valid_df = pd.DataFrame(X_valid)\n",
    "test_df = pd.DataFrame(X_test)\n",
    "\n",
    "train_df['label'] = y_train_encode.tolist()\n",
    "valid_df['label'] = y_valid_encode.tolist()\n",
    "test_df['label'] = y_test_encode.tolist()\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "ds = DatasetDict ({\n",
    " 'train': Dataset.from_pandas(train_df),\n",
    " 'validation': Dataset.from_pandas(valid_df),\n",
    " 'test': Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 873\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 122\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Fine-tuning ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# setting device on GPU if available, else CPU\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(…)ge_Summary_BERT/resolve/main/config.json: 100%|████████████████████████████████████████████| 385/385 [00:00<?, ?B/s]\n",
      "C:\\Users\\kcaro\\miniconda3\\envs\\clinical-adapter\\lib\\site-packages\\huggingface_hub\\file_download.py:138: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kcaro\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "(…)arge_Summary_BERT/resolve/main/vocab.txt: 100%|██████████████████████████████████| 213k/213k [00:00<00:00, 3.68MB/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████| 436M/436M [00:39<00:00, 11.0MB/s]\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModel \n",
    "tokenizer_clinical_bio  = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\",model_max_length=150)\n",
    "model_clinical = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\", \n",
    "                                                                    num_labels=3,id2label={0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (shared_parameters): ModuleDict()\n",
       "  (bert): BertModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clinical = model_clinical.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(28997, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\"additional_special_tokens\": [\"[entity]\"]}\n",
    "num_added_toks = tokenizer_clinical_bio.add_special_tokens(special_tokens_dict,False)\n",
    "\n",
    "print(\"We have added\", num_added_toks, \"tokens\")\n",
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "model_clinical.resize_token_embeddings(len(tokenizer_clinical_bio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer_clinical_bio(example[\"sentence\"],   padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 873/873 [00:00<00:00, 10124.42 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 219/219 [00:00<00:00, 8974.36 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 21061.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "tokenized_ds = tokenized_ds.remove_columns([\"sentence\"])\n",
    "tokenized_ds = tokenized_ds.remove_columns([\"__index_level_0__\"])\n",
    "tokenized_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"clinbert_trainer\", evaluation_strategy=\"epoch\", learning_rate=1e-5, num_train_epochs=1,)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_clinical,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\miniconda3\\envs\\clinical-adapter\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 873\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 110\n",
      "  Number of trainable parameters = 108313347\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 15/110 27:33 < 3:21:23, 0.01 it/s, Epoch 0.13/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical-adapter",
   "language": "python",
   "name": "clinical-adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
