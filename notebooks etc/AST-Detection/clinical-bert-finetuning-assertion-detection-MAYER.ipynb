{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning ClinicalBERT for clinical assertion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post, we will show how to fine-tune a bert language model for a downstream task: clinical assertion detection. We are going to leverage the Hugging Face transformer library and the model hub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show how  :\n",
    "\n",
    "1. Load and prepare the data for assertion dectection\n",
    "\n",
    "2. Fine-tune an auto-encoding language model such as Clinical BERT\n",
    "\n",
    "3. Evaluate and run Inference with the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Background and Context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical assertion dectection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is based on the paper \"Assertion Detection in Clinical Notes: Medical Language Models to the Rescue?\" , using Language model for assertion detection. Assertion detection is the task to identify the assertion of an entity based on textual cues in unstructured text. In other words we want to classify the assertions made on given medical concepts as being :\n",
    "* present\n",
    "* absent\n",
    "* possible in the patient\n",
    "* conditionally present in the patient under certain circumstances\n",
    "* hypothtically present in the patient at some future point\n",
    "* mentioned in the patient report but associated with somenone else\n",
    "\n",
    "For example given the text \"The patient recovered during the night and now denies any shortness of breath.\", the model should identify that the entity: shortness of breath is absent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo we use The 2010 i2b2/VA Workshop on Natural Language Processing Challenges for Clinical Records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; \n",
    "and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. These are be available to the research community from [i2b2](https://i2b2.org/NLP/DataSets) portal under data use agreements. For more information please consult the paper [2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text](https://academic.oup.com/jamia/article/18/5/552/830538)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to request access, download and extract  the data needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the Pytorch and HuggingFace library, an run the experiemnt on a Google Colab. You will also need to install spacy and the biomedical pretrained model  **en_ner_bc5cdr_md** a spaCy NER model trained on the BC5CDR corpus. The model en_ner_bc5cdr_md was trained for DISEASE and CHEMICAL entity recognition. To install all the dependencies run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all the libraries and dependencies\n",
    "#%pip install -r requirements.txt\n",
    "#python=3.8\n",
    "# conda install matplotlib numpy scikit-learn\n",
    "# conda install pandas\n",
    "# pip install spacy\n",
    "# pip install scispacy ? gave error ignored\n",
    "# pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
    "# conda install pytorch torchvision -c pytorch\n",
    "# pip install ipykernel\n",
    "# pip install transformers\n",
    "# pip install datasets\n",
    "# pip install evaluate\n",
    "# pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the assertion classification data from i2b2, which consist of XXXXX records of discharge summary notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\Documents\\GitHub\\clinical-adapter\\Data/concept_assertion_relation_training_data\\beth\\ast\n",
      "C:\\Users\\kcaro\\Documents\\GitHub\\clinical-adapter\\Data/concept_assertion_relation_training_data\\beth\\txt\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd  = os.getcwd()\n",
    "labels_path = os.path.join(cwd,\"Data/concept_assertion_relation_training_data\",\"beth\",\"ast\")\n",
    "data_path = os.path.join(cwd,\"Data/concept_assertion_relation_training_data\",\"beth\",\"txt\")\n",
    "\n",
    "print(labels_path)\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the files names\n",
    "records = [i for i in range(13, 39)]\n",
    "records = records + [i for i in range(45, 57)]\n",
    "records = records + [58,59]\n",
    "records = records + [i for i in range(65, 71)]\n",
    "records = records + [73,74]\n",
    "records = records + [i for i in range(81, 85)]\n",
    "records = records + [i for i in range(105,109)]\n",
    "records = records + [i for i in range(121,125)]\n",
    "records = records + [i for i in range(140,145)]\n",
    "records = records + [i for i in range(175,180)]\n",
    "records_files = [f\"record-{i}.txt\" for i in records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function which loops in text files list and read each file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_notes(records_files):\n",
    "    # reading the data files in a list\n",
    "    content_records = []\n",
    "    for record in records_files:\n",
    "        _file = os.path.join(data_path,record)\n",
    "        with open(_file) as f:\n",
    "            content = f.read()\n",
    "            #lines = content.split(\"\\n\")\n",
    "            content_records.append((record[:-4],content))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return content_records\n",
    "\n",
    "content_records = load_clinical_notes(records_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split each note into sentences using spacy biomedical pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kcaro\\miniconda3\\envs\\clinical-adapter\\lib\\site-packages\\spacy\\util.py:887: UserWarning: [W095] Model 'en_ner_bc5cdr_md' (0.4.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import en_ner_bc5cdr_md\n",
    "import spacy\n",
    "\n",
    "def split_note_sentences(content_records):\n",
    "    # load spacy\n",
    "    nlp1 = spacy.load(\"en_ner_bc5cdr_md\",disable = ['parser'])\n",
    "    nlp1.add_pipe('sentencizer')\n",
    "\n",
    "    # transform the data into a list of sentences\n",
    "    docs = [(r,nlp1(text)) for r,text in content_records]\n",
    "    data = []\n",
    "    for r,doc in docs:\n",
    "        for s in doc.sents:\n",
    "            sentence = str.strip(str(s))\n",
    "            sentence = sentence.replace(\"\\n\",\" \")\n",
    "            data.append((r,sentence))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = split_note_sentences(content_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('record-13',\n",
       " 'Admission Date : 2018-10-25 Discharge Date : 2018-10-31 Date of Birth : 1951-06-15 Sex : M Service :  CARDIOTHORACIC Allergies : Patient recorded as having No Known Allergies to Drugs Attending : Michael D. Christensen , M.D. Chief Complaint : Shortness of Breath Major Surgical or Invasive Procedure : Coronary Artery Bypass Graft x3 ( Left internal mammary -> left anterior descending , saphaneous vein graft -> obtuse marginal , saphaneous vein graft -> posterior descending artery ) 2018-10-25 History of Present Illness : 67 y/o male with worsening shortness of breath.')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load and process the labels. They are provided as ast files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>assertion</th>\n",
       "      <th>label</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>coronary artery disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>left arm phlebitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record-13</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>further episodes of afib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>mildly thickened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>seasonal allergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>his embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>record-179</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>discoid lateral meniscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          record assertion    label                        entity\n",
       "0      record-13   present  problem       coronary artery disease\n",
       "1      record-13   present  problem  burst of atrial fibrillation\n",
       "2      record-13   present  problem            left arm phlebitis\n",
       "3      record-13    absent  problem      further episodes of afib\n",
       "4      record-13   present  problem              mildly thickened\n",
       "...          ...       ...      ...                           ...\n",
       "4107  record-179   present  problem            seasonal allergies\n",
       "4108  record-179   present  problem                   his embolus\n",
       "4109  record-179    absent  problem                         cough\n",
       "4110  record-179   present  problem      discoid lateral meniscus\n",
       "4111  record-179   present  problem             pulmonary embolus\n",
       "\n",
       "[4112 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "def load_notes_labels(records):\n",
    "\n",
    "    records_files_ast = [f\"record-{i}.ast\" for i in records]\n",
    "    \n",
    "    # load labels in a list\n",
    "    labels_records = []\n",
    "    for record in records_files_ast:\n",
    "        _file = os.path.join(labels_path,record)\n",
    "        #print(_file)\n",
    "        with open(_file) as f:\n",
    "            content = f.readlines()\n",
    "            file_data = []\n",
    "            for line in content:\n",
    "                ast = line.strip().split('||')\n",
    "                line_entity = []\n",
    "\n",
    "                assertion = ast[2].split('=')\n",
    "                entity_label = ast[1].split(\"=\")\n",
    "        \n",
    "                entity_text = re.findall('\"([^\"]*)\"', ast[0])\n",
    "\n",
    "                line_entity.append(record[:-4])\n",
    "                line_entity.append(assertion[1].replace('\"',''))\n",
    "                line_entity.append(entity_label[1].replace('\"',''))\n",
    "                line_entity.append(entity_text[0])\n",
    "                file_data.append(line_entity)\n",
    "        labels_records.append(file_data)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return labels_records\n",
    "\n",
    "labels_records  = load_notes_labels(records)\n",
    "\n",
    "# labels in a dataframe\n",
    "data_labels = [line for f in labels_records for line in f]\n",
    "df_data_labels = pd.DataFrame(data_labels,columns=['record','assertion','label','entity'])\n",
    "\n",
    "df_data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Annotate text for clinical assertion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing the data we need to annotate each entity in our training data between the token '[entity]' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # remove all non-ASCII characters:\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) \n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to map the data with the labels. We do so by using the record id and searching the entity name in the text to do the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linking_train_labels_data(data,df_data_labels):\n",
    "    new_data = []\n",
    "    for r , sent in data:\n",
    "        for index,row in df_data_labels.loc[df_data_labels['record'] == r,['entity','assertion']].iterrows():\n",
    "            entity = clean_text(row['entity'])\n",
    "            sentence = clean_text(sent)\n",
    "            #print(entity,sent)\n",
    "            try:\n",
    "                if re.search(r'\\b' + str(entity) + r'\\b', str(sentence)):\n",
    "                    new_data.append((r,entity,sentence,row['assertion']))\n",
    "            except:\n",
    "                print(r)\n",
    "                print(\"entity:\",str(entity))\n",
    "                print(\"****\")\n",
    "    return new_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = linking_train_labels_data(data,df_data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can annotate each sentence with the token [entity]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_data(new_data):\n",
    "    processed_data = []\n",
    "    for r,entity,text,label in new_data:\n",
    "        #print(text)\n",
    "        match = re.search(r'\\b' + entity + r'\\b',text)\n",
    "\n",
    "        res = list(text)\n",
    "        res.insert(match.start(), '[entity] ')\n",
    "        res.insert(match.end()+1, ' [entity]')\n",
    "        res = ''.join(res)\n",
    "        processed_data.append((r,entity,res,label))  \n",
    "\n",
    "    return processed_data\n",
    "\n",
    "processed_data =  annotate_data(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>assertion</th>\n",
       "      <th>label</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>coronary artery disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>left arm phlebitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record-13</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>further episodes of afib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>mildly thickened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>seasonal allergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>his embolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>record-179</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>cough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>discoid lateral meniscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>record-179</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>pulmonary embolus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          record assertion    label                        entity\n",
       "0      record-13   present  problem       coronary artery disease\n",
       "1      record-13   present  problem  burst of atrial fibrillation\n",
       "2      record-13   present  problem            left arm phlebitis\n",
       "3      record-13    absent  problem      further episodes of afib\n",
       "4      record-13   present  problem              mildly thickened\n",
       "...          ...       ...      ...                           ...\n",
       "4107  record-179   present  problem            seasonal allergies\n",
       "4108  record-179   present  problem                   his embolus\n",
       "4109  record-179    absent  problem                         cough\n",
       "4110  record-179   present  problem      discoid lateral meniscus\n",
       "4111  record-179   present  problem             pulmonary embolus\n",
       "\n",
       "[4112 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>assertion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronary artery disease</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left arm phlebitis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>further episodes of afib</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mildly thickened</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe 3 vessel disease</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mildly dilated</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>carpal tunnel syndrome</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>increased pain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>any weight gain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>any fever greater than 101</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>surgical incision</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incisions</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abnormal ett</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pain</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>redness</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>drainage</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>varicosities</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worsening shortness of breath.</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>edema</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>known allergies</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>simple atheroma in the descending thoracic aorta</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carpal tunnel syndrome</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bell's palsy</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mild inferior wall hypokinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aortic regurgitation</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aortic valve stenosis</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>shortness of breath</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pneumothorax</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>left lower lobe atelectasis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>trivial mitral regurgitation</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mild postoperative widening of the cardiomedia...</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mi</td>\n",
       "      <td>associated_with_someone_else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>w/r/r</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thinning of the mid to distal inferior septum</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>nc/at</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>akinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>carotid bruits</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mildly depressed</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dyskinesis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c/r/m/g</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wounds</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>infection</td>\n",
       "      <td>hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hoh</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>jvd</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nt/nd</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nad</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               entity  \\\n",
       "0                             coronary artery disease   \n",
       "1                        burst of atrial fibrillation   \n",
       "2                                  left arm phlebitis   \n",
       "3                            further episodes of afib   \n",
       "4                                    mildly thickened   \n",
       "5                             severe 3 vessel disease   \n",
       "6                                      mildly dilated   \n",
       "7                                        hypertension   \n",
       "8                              carpal tunnel syndrome   \n",
       "9                                      increased pain   \n",
       "10                                    any weight gain   \n",
       "11                         any fever greater than 101   \n",
       "12                                  surgical incision   \n",
       "13                                          incisions   \n",
       "14                                       abnormal ett   \n",
       "15                                               pain   \n",
       "16                                            redness   \n",
       "17                                           drainage   \n",
       "18                                          arthritis   \n",
       "19                                       varicosities   \n",
       "20                     worsening shortness of breath.   \n",
       "21                                     hyperlipidemia   \n",
       "22                                              edema   \n",
       "23                                       hypertension   \n",
       "24                                    known allergies   \n",
       "25   simple atheroma in the descending thoracic aorta   \n",
       "26                             carpal tunnel syndrome   \n",
       "27                                       bell's palsy   \n",
       "28                     mild inferior wall hypokinesis   \n",
       "29                               aortic regurgitation   \n",
       "30                              aortic valve stenosis   \n",
       "31                                shortness of breath   \n",
       "32                                       pneumothorax   \n",
       "33                        left lower lobe atelectasis   \n",
       "34                       trivial mitral regurgitation   \n",
       "35  mild postoperative widening of the cardiomedia...   \n",
       "36                                                 mi   \n",
       "37                                              w/r/r   \n",
       "38      thinning of the mid to distal inferior septum   \n",
       "39                                              nc/at   \n",
       "40                                           akinesis   \n",
       "41                                     carotid bruits   \n",
       "42                                   mildly depressed   \n",
       "43                                         dyskinesis   \n",
       "44                                            c/r/m/g   \n",
       "45                                             wounds   \n",
       "46                                          infection   \n",
       "47                                                hoh   \n",
       "48                                          arthritis   \n",
       "49                                     hyperlipidemia   \n",
       "50                                                jvd   \n",
       "51                                              nt/nd   \n",
       "52                                                nad   \n",
       "\n",
       "                       assertion  \n",
       "0                        present  \n",
       "1                        present  \n",
       "2                        present  \n",
       "3                         absent  \n",
       "4                        present  \n",
       "5                        present  \n",
       "6                        present  \n",
       "7                        present  \n",
       "8                        present  \n",
       "9                   hypothetical  \n",
       "10                  hypothetical  \n",
       "11                  hypothetical  \n",
       "12                       present  \n",
       "13                       present  \n",
       "14                       present  \n",
       "15                  hypothetical  \n",
       "16                  hypothetical  \n",
       "17                  hypothetical  \n",
       "18                       present  \n",
       "19                        absent  \n",
       "20                       present  \n",
       "21                       present  \n",
       "22                        absent  \n",
       "23                       present  \n",
       "24                        absent  \n",
       "25                       present  \n",
       "26                       present  \n",
       "27                       present  \n",
       "28                       present  \n",
       "29                        absent  \n",
       "30                        absent  \n",
       "31                       present  \n",
       "32                        absent  \n",
       "33                       present  \n",
       "34                       present  \n",
       "35                       present  \n",
       "36  associated_with_someone_else  \n",
       "37                        absent  \n",
       "38                       present  \n",
       "39                        absent  \n",
       "40                       present  \n",
       "41                        absent  \n",
       "42                       present  \n",
       "43                       present  \n",
       "44                        absent  \n",
       "45                       present  \n",
       "46                  hypothetical  \n",
       "47                       present  \n",
       "48                       present  \n",
       "49                       present  \n",
       "50                        absent  \n",
       "51                        absent  \n",
       "52                        absent  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_labels.loc[df_data_labels['record'] =='record-13' ,['entity','assertion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('record-13',\n",
       " 'known allergies',\n",
       " 'admission date 2018 10 25 discharge date 2018 10 31 date of birth 1951 06 15 sex m service cardiothoracic allergies patient recorded as having no [entity] known allergies [entity] to drugs attending michael d christensen m d chief complaint shortness of breath major surgical or invasive procedure coronary artery bypass graft x3 left internal mammary left anterior descending saphaneous vein graft obtuse marginal saphaneous vein graft posterior descending artery 2018 10 25 history of present illness 67 y o male with worsening shortness of breath',\n",
       " 'absent')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('record-13',\n",
    " 'known allergies',\n",
    " 'admission date 2018 10 25 discharge date 2018 10 31 date of birth 1951 06 15 sex m service cardiothoracic allergies patient recorded as having no [entity] known allergies [entity] to drugs attending michael d christensen m d chief complaint shortness of breath major surgical or invasive procedure coronary artery bypass graft x3 left internal mammary left anterior descending saphaneous vein graft obtuse marginal saphaneous vein graft posterior descending artery 2018 10 25 history of present illness 67 y o male with worsening shortness of breath',\n",
    " 'absent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally , we create a dataframe where for our example we only keep 3 assertions labels : present , absent and possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>had [entity] abnormal ett [entity] and referre...</td>\n",
       "      <td>present</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cath revealed [entity] severe 3 vessel disease...</td>\n",
       "      <td>present</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>medications on admission claritin prn flonase ...</td>\n",
       "      <td>present</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>the mri of your knee showed [entity] a menisca...</td>\n",
       "      <td>present</td>\n",
       "      <td>6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>the mri of your knee showed a [entity] menisca...</td>\n",
       "      <td>possible</td>\n",
       "      <td>6534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence     label   idx\n",
       "0     admission date 2018 10 25 discharge date 2018 ...   present     0\n",
       "1     admission date 2018 10 25 discharge date 2018 ...    absent     1\n",
       "2     admission date 2018 10 25 discharge date 2018 ...   present     2\n",
       "3     had [entity] abnormal ett [entity] and referre...   present     3\n",
       "4     cath revealed [entity] severe 3 vessel disease...   present     4\n",
       "...                                                 ...       ...   ...\n",
       "6530  medications on admission claritin prn flonase ...   present  6530\n",
       "6531  medications on admission claritin prn flonase ...   present  6531\n",
       "6532  medications on admission claritin prn flonase ...   present  6532\n",
       "6533  the mri of your knee showed [entity] a menisca...   present  6533\n",
       "6534  the mri of your knee showed a [entity] menisca...  possible  6534\n",
       "\n",
       "[6072 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data = [{'sentence':text , 'label':label,'idx':idx} for idx,(r, entity, text,label) in enumerate(processed_data)]\n",
    "\n",
    "df_i2b2 = pd.DataFrame(prepare_data)\n",
    "df_i2b2 = df_i2b2[(df_i2b2.label=='present') | (df_i2b2.label=='absent') | (df_i2b2.label=='possible') ].copy()\n",
    "df_i2b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    admission date 2018 10 25 discharge date 2018 ...\n",
       "label                                                 present\n",
       "idx                                                         0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i2b2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>assertion</th>\n",
       "      <th>label</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>coronary artery disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>burst of atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>left arm phlebitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record-13</td>\n",
       "      <td>absent</td>\n",
       "      <td>problem</td>\n",
       "      <td>further episodes of afib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record-13</td>\n",
       "      <td>present</td>\n",
       "      <td>problem</td>\n",
       "      <td>mildly thickened</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      record assertion    label                        entity\n",
       "0  record-13   present  problem       coronary artery disease\n",
       "1  record-13   present  problem  burst of atrial fibrillation\n",
       "2  record-13   present  problem            left arm phlebitis\n",
       "3  record-13    absent  problem      further episodes of afib\n",
       "4  record-13   present  problem              mildly thickened"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admission date 2018 10 25 discharge date 2018 ...</td>\n",
       "      <td>present</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>had [entity] abnormal ett [entity] and referre...</td>\n",
       "      <td>present</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cath revealed [entity] severe 3 vessel disease...</td>\n",
       "      <td>present</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    label  idx\n",
       "0  admission date 2018 10 25 discharge date 2018 ...  present    0\n",
       "1  admission date 2018 10 25 discharge date 2018 ...   absent    1\n",
       "2  admission date 2018 10 25 discharge date 2018 ...  present    2\n",
       "3  had [entity] abnormal ett [entity] and referre...  present    3\n",
       "4  cath revealed [entity] severe 3 vessel disease...  present    4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i2b2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6072, 4112)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why isn't the i2b2 dataset the same length as the df_data_labels?\n",
    "len(df_i2b2), len(df_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are [entity] simple atheroma in the descending thoracic aorta [entity]  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic root  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic root  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic root  - l: present\n",
      "there are [entity] simple atheroma [entity] in the ascending aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the ascending aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the ascending aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the ascending aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic arch  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic arch  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic arch  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic arch  - l: present\n",
      "there are [entity] simple atheroma [entity] in the descending thoracic aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the descending thoracic aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the descending thoracic aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the descending thoracic aorta  - l: present\n"
     ]
    }
   ],
   "source": [
    "# Example of repeat data\n",
    "print(df_i2b2['sentence'][31], \" - l:\", df_i2b2['label'][31])\n",
    "print(df_i2b2['sentence'][4488], \" - l:\", df_i2b2['label'][4488])\n",
    "print(df_i2b2['sentence'][4489], \" - l:\", df_i2b2['label'][4489])\n",
    "print(df_i2b2['sentence'][4490], \" - l:\", df_i2b2['label'][4490])\n",
    "print(df_i2b2['sentence'][4492], \" - l:\", df_i2b2['label'][4492])\n",
    "print(df_i2b2['sentence'][4493], \" - l:\", df_i2b2['label'][4493])\n",
    "print(df_i2b2['sentence'][4494], \" - l:\", df_i2b2['label'][4494])\n",
    "print(df_i2b2['sentence'][4495], \" - l:\", df_i2b2['label'][4495])\n",
    "print(df_i2b2['sentence'][4496], \" - l:\", df_i2b2['label'][4496])\n",
    "print(df_i2b2['sentence'][4497], \" - l:\", df_i2b2['label'][4497])\n",
    "print(df_i2b2['sentence'][4498], \" - l:\", df_i2b2['label'][4498])\n",
    "print(df_i2b2['sentence'][4499], \" - l:\", df_i2b2['label'][4499])\n",
    "print(df_i2b2['sentence'][4500], \" - l:\", df_i2b2['label'][4500])\n",
    "print(df_i2b2['sentence'][4501], \" - l:\", df_i2b2['label'][4501])\n",
    "print(df_i2b2['sentence'][4502], \" - l:\", df_i2b2['label'][4502])\n",
    "print(df_i2b2['sentence'][4503], \" - l:\", df_i2b2['label'][4503])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 4112\n",
      "num in data: 4403\n"
     ]
    }
   ],
   "source": [
    "# However, even when we drop duplicates, there appears to be extra data that does not belong\n",
    "df_i2b2_dropped = df_i2b2[['sentence', 'label']]\n",
    "df_i2b2_dropped = df_i2b2_dropped.drop_duplicates()\n",
    "print(\"num labels:\", len(df_data_labels))\n",
    "print(\"num in data:\", len(df_i2b2_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are [entity] simple atheroma [entity] in the aortic root  - l: present\n",
      "there are [entity] simple atheroma [entity] in the ascending aorta  - l: present\n",
      "there are [entity] simple atheroma [entity] in the aortic arch  - l: present\n",
      "there are [entity] simple atheroma [entity] in the descending thoracic aorta  - l: present\n"
     ]
    }
   ],
   "source": [
    "# Example of repeat data\n",
    "# print(\"s:\", df_i2b2['sentence'][31], \" - l:\", df_i2b2['label'][31])\n",
    "print(df_i2b2_dropped['sentence'][4488], \" - l:\", df_i2b2['label'][4488])\n",
    "# print(df_i2b2_dropped['sentence'][4489], \" - l:\", df_i2b2['label'][4489])\n",
    "# print(df_i2b2_dropped['sentence'][4490], \" - l:\", df_i2b2['label'][4490])\n",
    "print(df_i2b2_dropped['sentence'][4492], \" - l:\", df_i2b2['label'][4492])\n",
    "# print(df_i2b2_dropped['sentence'][4493], \" - l:\", df_i2b2['label'][4493])\n",
    "# print(df_i2b2_dropped['sentence'][4494], \" - l:\", df_i2b2['label'][4494])\n",
    "# print(df_i2b2_dropped['sentence'][4495], \" - l:\", df_i2b2['label'][4495])\n",
    "print(df_i2b2_dropped['sentence'][4496], \" - l:\", df_i2b2['label'][4496])\n",
    "# print(df_i2b2_dropped['sentence'][4497], \" - l:\", df_i2b2['label'][4497])\n",
    "# print(df_i2b2_dropped['sentence'][4498], \" - l:\", df_i2b2['label'][4498])\n",
    "# print(df_i2b2_dropped['sentence'][4499], \" - l:\", df_i2b2['label'][4499])\n",
    "print(df_i2b2_dropped['sentence'][4500], \" - l:\", df_i2b2['label'][4500])\n",
    "# print(df_i2b2_dropped['sentence'][4501], \" - l:\", df_i2b2['label'][4501])\n",
    "# print(df_i2b2_dropped['sentence'][4502], \" - l:\", df_i2b2['label'][4502])\n",
    "# print(df_i2b2_dropped['sentence'][4503], \" - l:\", df_i2b2['label'][4503])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Splitting the data and create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sklearn to split the data into train, validation and test set. We have 80% for training, 10% for testing and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (873,) y_train shape : (873,)\n",
      "X_valid shape (219,) y_valid shape : (219,)\n",
      "X_test shape (122,) y_test shape : (122,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_i2b2 = df_i2b2.sample(frac=0.2).copy()\n",
    "\n",
    "X = df_i2b2['sentence']\n",
    "y = df_i2b2['label']\n",
    "\n",
    "X_train_valid,X_test,y_train_valid, y_test= train_test_split(X,y,test_size=0.1,stratify=y,random_state=42)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_valid,y_train_valid,train_size=0.8,random_state=42,stratify=y_train_valid)\n",
    "\n",
    "print(f\"X_train shape {X_train.shape} y_train shape : {y_train.shape}\")\n",
    "print(f\"X_valid shape {X_valid.shape} y_valid shape : {y_valid.shape}\")\n",
    "print(f\"X_test shape {X_test.shape} y_test shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(873,) (873,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['present', 'present', 'absent', ..., 'present', 'present',\n",
       "        'absent'],\n",
       "       ['[entity] prematurity [entity] at 30 6 7 weeks',\n",
       "        'impression unchanged moderate [entity] bilateral pleural effusions [entity] and mild chf',\n",
       "        'nicholas seizures no [entity] loc [entity] no head or neck trauma',\n",
       "        ...,\n",
       "        'discharge diagnosis [entity] st elevation myocardial infarction [entity] status post left anterior descending artery stent',\n",
       "        'status post tracheostomy 2017 07 21 02 22 [entity] failure to wean [entity] 14',\n",
       "        'no [entity] lymphadenopathy [entity]']], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(X_train.shape,y_train.shape)\n",
    "np.vstack((y_train,X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use sklearn to encode our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Labels .....\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Encoding Labels .....\")\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train_encode = np.asarray(encoder.transform(y_train))\n",
    "y_valid_encode = np.asarray(encoder.transform(y_valid))\n",
    "y_test_encode = np.asarray(encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4702        [entity] prematurity [entity] at 30 6 7 weeks\n",
       "3295    impression unchanged moderate [entity] bilater...\n",
       "1850    nicholas seizures no [entity] loc [entity] no ...\n",
       "6506           syncope in setting of [entity] pe [entity]\n",
       "2465    pt s [entity] hypertensive urgency [entity] wa...\n",
       "                              ...                        \n",
       "562     left upper extremity examination demonstrated ...\n",
       "6438    social history lives w wife son in jose ma den...\n",
       "3837    discharge diagnosis [entity] st elevation myoc...\n",
       "5801    status post tracheostomy 2017 07 21 02 22 [ent...\n",
       "5247                 no [entity] lymphadenopathy [entity]\n",
       "Name: sentence, Length: 873, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayerantoine/miniforge3/envs/negation-detection/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               sentence  label\n",
      "4702      [entity] prematurity [entity] at 30 6 7 weeks      2\n",
      "3295  impression unchanged moderate [entity] bilater...      2\n",
      "1850  nicholas seizures no [entity] loc [entity] no ...      0\n",
      "6506         syncope in setting of [entity] pe [entity]      2\n",
      "2465  pt s [entity] hypertensive urgency [entity] wa...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(X_train)\n",
    "valid_df = pd.DataFrame(X_valid)\n",
    "test_df = pd.DataFrame(X_test)\n",
    "\n",
    "train_df['label'] = y_train_encode.tolist()\n",
    "valid_df['label'] = y_valid_encode.tolist()\n",
    "test_df['label'] = y_test_encode.tolist()\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "ds = DatasetDict ({\n",
    " 'train': Dataset.from_pandas(train_df),\n",
    " 'validation': Dataset.from_pandas(valid_df),\n",
    " 'test': Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 873\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', '__index_level_0__'],\n",
       "        num_rows: 122\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Fine-tuning ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# setting device on GPU if available, else CPU\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModel \n",
    "tokenizer_clinical_bio  = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\",model_max_length=150)\n",
    "model_clinical = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\", \n",
    "                                                                    num_labels=3,id2label={0: 'PRESENT', 1: 'ABSENT', 2:'POSSIBLE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clinical = model_clinical.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(28997, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\"additional_special_tokens\": [\"[entity]\"]}\n",
    "num_added_toks = tokenizer_clinical_bio.add_special_tokens(special_tokens_dict,False)\n",
    "\n",
    "print(\"We have added\", num_added_toks, \"tokens\")\n",
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "model_clinical.resize_token_embeddings(len(tokenizer_clinical_bio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer_clinical_bio(example[\"sentence\"],   padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/873 [00:00<?, ? examples/s]Map: 100%|██████████| 873/873 [00:00<00:00, 12339.43 examples/s]\n",
      "Map: 100%|██████████| 219/219 [00:00<00:00, 2047.84 examples/s]\n",
      "Map: 100%|██████████| 122/122 [00:00<00:00, 12725.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "tokenized_ds = tokenized_ds.remove_columns([\"sentence\"])\n",
    "tokenized_ds = tokenized_ds.remove_columns([\"__index_level_0__\"])\n",
    "tokenized_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"clinbert_trainer\", evaluation_strategy=\"epoch\", learning_rate=1e-5, num_train_epochs=1,)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_clinical,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds['train'],\n",
    "    eval_dataset=tokenized_ds['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 110/110 [00:56<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5837724804878235, 'eval_accuracy': 0.7625570776255708, 'eval_runtime': 3.5802, 'eval_samples_per_second': 61.17, 'eval_steps_per_second': 7.821, 'epoch': 1.0}\n",
      "{'train_runtime': 57.0262, 'train_samples_per_second': 15.309, 'train_steps_per_second': 1.929, 'train_loss': 0.6306253606622869, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=0.6306253606622869, metrics={'train_runtime': 57.0262, 'train_samples_per_second': 15.309, 'train_steps_per_second': 1.929, 'train_loss': 0.6306253606622869, 'epoch': 1.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5837724804878235,\n",
       " 'eval_accuracy': 0.7625570776255708,\n",
       " 'eval_runtime': 3.1911,\n",
       " 'eval_samples_per_second': 68.628,\n",
       " 'eval_steps_per_second': 8.774,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical-adapter",
   "language": "python",
   "name": "clinical-adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
